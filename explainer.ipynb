{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = ((data_graph.y == 0).nonzero(as_tuple=True))[0].to(torch.float)\n",
    "num_samples = 5\n",
    "random_indices = torch.multinomial(indices, num_samples, replacement=True)\n",
    "random_elements = indices[random_indices]\n",
    "random_elements\n",
    "\n",
    "indices = ((data_graph.y == 1).nonzero(as_tuple=True))[0].to(torch.float)\n",
    "random_indices = torch.multinomial(indices, num_samples, replacement=True)\n",
    "random_elements_2 = indices[random_indices]\n",
    "ind = torch.cat((random_elements, random_elements_2), dim=0).to(torch.int)\n",
    "ind.tolist()\n",
    "feat = data_graph.x[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "exp = []\n",
    "# explanations for each node\n",
    "for i in ind:\n",
    "    explanation = explainer(data_graph.x, data_graph.edge_index, index=i)\n",
    "    exp.append(explanation)\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in exp:\n",
    "    path = f'features/feature_importance{e.index}.png'\n",
    "    e.visualize_feature_importance(path, top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing, APPNP\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "def subgraph(model, node_idx, x, edge_index, **kwargs):\n",
    "    num_nodes, num_edges = x.size(0), edge_index.size(1)\n",
    "\n",
    "    flow = 'source_to_target'\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, MessagePassing):\n",
    "            flow = module.flow\n",
    "            break\n",
    "\n",
    "    num_hops = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, MessagePassing):\n",
    "            if isinstance(module, APPNP):\n",
    "                num_hops += module.K\n",
    "            else:\n",
    "                num_hops += 1\n",
    "\n",
    "    subset, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "        node_idx, num_hops, edge_index, relabel_nodes=True,\n",
    "        num_nodes=num_nodes, flow=flow)\n",
    "\n",
    "    x = x[subset]\n",
    "    for key, item in kwargs:\n",
    "        if torch.is_tensor(item) and item.size(0) == num_nodes:\n",
    "            item = item[subset]\n",
    "        elif torch.is_tensor(item) and item.size(0) == num_edges:\n",
    "            item = item[edge_mask]\n",
    "        kwargs[key] = item\n",
    "\n",
    "    return x, edge_index, mapping, edge_mask, kwargs\n",
    "\n",
    "def edge_mask_to_node_mask(data, edge_mask, aggregation=\"mean\"):\n",
    "\n",
    "    node_weights = torch.zeros(data.x.shape[0])\n",
    "\n",
    "    if aggregation == \"sum\":\n",
    "\n",
    "        for weight, nodes in zip(edge_mask, data.edge_index.T):\n",
    "            node_weights[nodes[0].item()] += weight.item() / 2\n",
    "            node_weights[nodes[1].item()] += weight.item() / 2\n",
    "\n",
    "    elif aggregation == \"mean\":\n",
    "\n",
    "        node_degrees = torch.zeros(data.x.shape[0])\n",
    "\n",
    "        for weight, nodes in zip(edge_mask, data.edge_index.T):\n",
    "\n",
    "            node_weights[nodes[0].item()] += weight.item()\n",
    "\n",
    "            node_weights[nodes[1].item()] += weight.item()\n",
    "\n",
    "            node_degrees[nodes[0].item()] += 1\n",
    "\n",
    "            node_degrees[nodes[1].item()] += 1\n",
    "\n",
    "        node_weights = node_weights / node_degrees.clamp(min=1.)\n",
    "\n",
    "    elif aggregation == \"max\":\n",
    "\n",
    "        for weight, nodes in zip(edge_mask, data.edge_index.T):\n",
    "\n",
    "            node_weights[nodes[0].item()] = max(weight.item(), node_weights[nodes[0].item()])\n",
    "\n",
    "            node_weights[nodes[1].item()] = max(weight.item(), node_weights[nodes[1].item()])\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise NotImplementedError(f\"No such aggregation method: {aggregation}\")\n",
    "\n",
    "    return node_weights\n",
    "\n",
    "# convert the edge mask to node mask here\n",
    "def generate_node_masks(explainer, nodes, data, aggregation=\"mean\"):\n",
    "    node_masks = []\n",
    "\n",
    "    for node in nodes:\n",
    "        _, edge_mask = explainer.explain_node(node, data.x, data.edge_index)\n",
    "        node_mask = edge_mask_to_node_mask(data, edge_mask, aggregation)\n",
    "        node_masks.append(node_mask)\n",
    "        \n",
    "    return node_masks\n",
    "\n",
    "# The function to return the k-hop subgraph of the selected nodes\n",
    "def fidelity(model,  # is a must\n",
    "             node_idx,  # is a must\n",
    "             full_feature_matrix,  # must\n",
    "             edge_index=None,  # the whole, so data.edge_index\n",
    "             node_mask=None,  # at least one of these three node, feature, edge\n",
    "             feature_mask=None,\n",
    "             edge_mask=None,\n",
    "             samples=100,\n",
    "             random_seed=12345,\n",
    "             device=\"cpu\"\n",
    "             ):\n",
    "    \"\"\"\n",
    "    Distortion/Fidelity (for Node Classification)\n",
    "    :param model: GNN model which is explained\n",
    "    :param node_idx: The node which is explained\n",
    "    :param full_feature_matrix: The feature matrix from the Graph (X)\n",
    "    :param edge_index: All edges\n",
    "    :param node_mask: Is a (binary) tensor with 1/0 for each node in the computational graph\n",
    "    => 1 means the features of this node will be fixed\n",
    "    => 0 means the features of this node will be pertubed/randomized\n",
    "    if not available torch.ones((1, num_computation_graph_nodes))\n",
    "    :param feature_mask: Is a (binary) tensor with 1/0 for each feature\n",
    "    => 1 means this features is fixed for all nodes with 1\n",
    "    => 0 means this feature is randomized for all nodes\n",
    "    if not available torch.ones((1, number_of_features))\n",
    "    :param edge_mask:\n",
    "    :param samples:\n",
    "    :param random_seed:\n",
    "    :param device:\n",
    "    :param validity:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if edge_mask is None and feature_mask is None and node_mask is None:\n",
    "        raise ValueError(\"At least supply one mask\")\n",
    "\n",
    "    computation_graph_feature_matrix, computation_graph_edge_index, mapping, hard_edge_mask, kwargs = subgraph(model, node_idx, \n",
    "                                                                                                               full_feature_matrix, \n",
    "                                                                                                               edge_index)\n",
    "\n",
    "    # get predicted label\n",
    "    log_logits = model.forward(x=computation_graph_feature_matrix,\n",
    "                               edge_index=computation_graph_edge_index)\n",
    "    predicted_labels = log_logits.argmax(dim=-1)\n",
    "\n",
    "    predicted_label = predicted_labels[mapping]\n",
    "\n",
    "    # fill missing masks\n",
    "    if feature_mask is None:\n",
    "        (num_nodes, num_features) = full_feature_matrix.size()\n",
    "        feature_mask= torch.ones((1, num_features), device=device)\n",
    "\n",
    "    num_computation_graph_nodes = computation_graph_feature_matrix.size(0)\n",
    "    if node_mask is None:\n",
    "        # all nodes selected\n",
    "        node_mask = torch.ones((1, num_computation_graph_nodes), device=device)\n",
    "\n",
    "\n",
    "    # set edge mask\n",
    "    if edge_mask is not None:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = edge_mask\n",
    "    (num_nodes, num_features) = full_feature_matrix.size()\n",
    "\n",
    "    num_nodes_computation_graph = computation_graph_feature_matrix.size(0)\n",
    "\n",
    "    # retrieve complete mask as matrix\n",
    "    mask = node_mask.T.matmul(feature_mask)\n",
    "\n",
    "    correct = 0.0\n",
    "\n",
    "    rng = torch.Generator(device=device)\n",
    "    rng.manual_seed(random_seed)\n",
    "    random_indices = torch.randint(num_nodes, (samples, num_nodes_computation_graph, num_features),\n",
    "                                   generator=rng,\n",
    "                                   device=device,\n",
    "                                   )\n",
    "    random_indices = random_indices.type(torch.int64)\n",
    "    \n",
    "    \n",
    "    ###################################################################################################\n",
    "    # for each samples, add your code here to:\n",
    "    for i in range(samples):\n",
    "\n",
    "        #1. generate the perturbed input\n",
    "        random_features = torch.gather(full_feature_matrix,\n",
    "                                       dim=0,\n",
    "                                       index=random_indices[i, :, :])\n",
    "\n",
    "        randomized_features = mask * computation_graph_feature_matrix + (1 - mask) * random_features\n",
    "\n",
    "        #2. get the prediction from the trained model using the perturbed features as input\n",
    "        log_logits = model(x=randomized_features, edge_index=computation_graph_edge_index)\n",
    "\n",
    "        #3. calculate the number of corrected predicted labels:\n",
    "        distorted_labels = log_logits.argmax(dim=-1)\n",
    "        if distorted_labels[mapping] == predicted_label:\n",
    "            correct += 1       \n",
    "    ###################################################################################################\n",
    "    \n",
    "    # reset mask\n",
    "    if edge_mask is not None:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                module.__explain__ = False\n",
    "                module.__edge_mask__ = None\n",
    "\n",
    "    return correct / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each node calculate the rdt fidelity for the feature and node mask\n",
    "\n",
    "# Initialize empty lists to store the results\n",
    "fidelity_scores = []\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Loop over each node\n",
    "for idx, explanation in zip(ind, exp):\n",
    "    # Generate masks for GNNExplainer\n",
    "    node_feat_mask = explanation.node_mask\n",
    "    # print(node_feat_mask)\n",
    "    edge_mask = explanation.edge_mask\n",
    "\n",
    "    node_mask = edge_mask_to_node_mask(data_graph, edge_mask, aggregation=\"mean\")\n",
    "\n",
    "    # Calculate fidelity\n",
    "    fidelity_score = fidelity(model, \n",
    "                              node_idx=idx, \n",
    "                              full_feature_matrix=data_graph.x, \n",
    "                              edge_index=data_graph.edge_index, \n",
    "                              node_mask=node_mask, \n",
    "                              edge_mask=edge_mask,\n",
    "                              feature_mask=node_feat_mask,\n",
    "                              device=device)\n",
    "    fidelity_scores.append(fidelity_score)\n",
    "\n",
    "# Print out the results\n",
    "for i, fid in zip(ind, fidelity_scores):\n",
    "    print(f'Node {i} - Fidelity: {fid}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
