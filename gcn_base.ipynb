{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import Linear, LayerNorm, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import ChebConv, NNConv, DeepGCNLayer, GATConv, DenseGCNConv, GCNConv, GraphConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ref: https://www.kaggle.com/code/divyareddyyeruva/elliptic-gcn-pyg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate txId:  0\n"
     ]
    }
   ],
   "source": [
    "# import data \n",
    "df_features = pd.read_csv('data/elliptic_txs_features.csv', header=None)\n",
    "df_edges = pd.read_csv(\"data/elliptic_txs_edgelist.csv\")\n",
    "df_classes =  pd.read_csv(\"data/elliptic_txs_classes.csv\")\n",
    "# map unknown classes to 0\n",
    "df_classes['class'] = df_classes['class'].apply(lambda x: 0 if x == \"unknown\" else int(x))\n",
    "\n",
    "# merging dataframes\n",
    "df_merge = df_features.merge(df_classes, how='left', right_on=\"txId\", left_on=0)\n",
    "df_merge.drop(0, axis=1, inplace=True)\n",
    "\n",
    "# check if there are duplicate txId\n",
    "print(\"Number of duplicate txId: \", df_merge.duplicated(subset=['txId']).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46564, 168)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(234355, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove unknown classes from df_merge\n",
    "df_merge = df_merge[df_merge[\"class\"] != 0]\n",
    "\n",
    "display(df_merge.shape)\n",
    "display(df_edges.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>txId</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>-0.163645</td>\n",
       "      <td>-0.115831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>232438397</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.005027</td>\n",
       "      <td>0.578941</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>4.380281</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>4.667146</td>\n",
       "      <td>0.851305</td>\n",
       "      <td>-0.163645</td>\n",
       "      <td>-0.144554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.604120</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.333211</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>232029206</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.147852</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.137933</td>\n",
       "      <td>-0.144108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>232344069</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.151357</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.141519</td>\n",
       "      <td>-0.147643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>27553029</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.172306</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.029140</td>\n",
       "      <td>0.242712</td>\n",
       "      <td>-0.163640</td>\n",
       "      <td>-0.169115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.068266</td>\n",
       "      <td>-0.084674</td>\n",
       "      <td>-0.054450</td>\n",
       "      <td>-1.760926</td>\n",
       "      <td>-1.760984</td>\n",
       "      <td>3881097</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136241</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.172968</td>\n",
       "      <td>-0.071395</td>\n",
       "      <td>0.463609</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163627</td>\n",
       "      <td>-0.169442</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>119222131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136243</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.172924</td>\n",
       "      <td>-0.107411</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163583</td>\n",
       "      <td>-0.169398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>77410785</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136249</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.172897</td>\n",
       "      <td>-0.070152</td>\n",
       "      <td>0.463609</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163555</td>\n",
       "      <td>-0.169371</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>288397726</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136250</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.155367</td>\n",
       "      <td>-0.081852</td>\n",
       "      <td>0.463609</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.145619</td>\n",
       "      <td>-0.151686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>227494727</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136258</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.172981</td>\n",
       "      <td>-0.070152</td>\n",
       "      <td>0.463609</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163641</td>\n",
       "      <td>-0.169455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>238473788</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29894 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1         2         3         4          5         6         7  \\\n",
       "3        1  0.163054  1.963790 -0.646376  12.409294 -0.063725  9.782742   \n",
       "9        1 -0.005027  0.578941 -0.091383   4.380281 -0.063725  4.667146   \n",
       "10       1 -0.147852 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "11       1 -0.151357 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "16       1 -0.172306 -0.184668 -1.201369   0.028105 -0.043875 -0.029140   \n",
       "...     ..       ...       ...       ...        ...       ...       ...   \n",
       "136241  34 -0.172968 -0.071395  0.463609  -0.121970 -0.043875 -0.113002   \n",
       "136243  34 -0.172924 -0.107411  1.018602  -0.121970 -0.063725 -0.113002   \n",
       "136249  34 -0.172897 -0.070152  0.463609  -0.121970 -0.043875 -0.113002   \n",
       "136250  34 -0.155367 -0.081852  0.463609  -0.121970 -0.043875 -0.113002   \n",
       "136258  34 -0.172981 -0.070152  0.463609  -0.121970 -0.043875 -0.113002   \n",
       "\n",
       "                8         9        10  ...       159       160       161  \\\n",
       "3       12.414558 -0.163645 -0.115831  ...  0.241128  0.241406  1.072793   \n",
       "9        0.851305 -0.163645 -0.144554  ...  0.241128  0.241406  0.604120   \n",
       "10      -0.061584 -0.137933 -0.144108  ...  0.241128  0.241406  0.018279   \n",
       "11      -0.061584 -0.141519 -0.147643  ... -0.979074 -0.978556  0.018279   \n",
       "16       0.242712 -0.163640 -0.169115  ...  0.241128  0.241406  0.018279   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "136241  -0.061584 -0.163627 -0.169442  ...  1.461330  1.461369 -0.098889   \n",
       "136243  -0.061584 -0.163583 -0.169398  ...  0.241128  0.241406 -0.098889   \n",
       "136249  -0.061584 -0.163555 -0.169371  ...  1.461330  1.461369  0.018279   \n",
       "136250  -0.061584 -0.145619 -0.151686  ...  0.241128  0.241406  0.018279   \n",
       "136258  -0.061584 -0.163641 -0.169455  ...  0.241128  0.241406 -0.098889   \n",
       "\n",
       "             162       163       164       165       166       txId  class  \n",
       "3       0.085530 -0.131155  0.677799 -0.120613 -0.119792  232438397      2  \n",
       "9       0.008632 -0.131155  0.333211 -0.120613 -0.119792  232029206      2  \n",
       "10     -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  232344069      2  \n",
       "11     -0.087490 -0.131155 -0.097524 -0.120613 -0.119792   27553029      2  \n",
       "16     -0.068266 -0.084674 -0.054450 -1.760926 -1.760984    3881097      2  \n",
       "...          ...       ...       ...       ...       ...        ...    ...  \n",
       "136241 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792  119222131      2  \n",
       "136243 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792   77410785      1  \n",
       "136249 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  288397726      2  \n",
       "136250 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  227494727      2  \n",
       "136258 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792  238473788      2  \n",
       "\n",
       "[29894 rows x 168 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>txId</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136276</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.172982</td>\n",
       "      <td>-0.055242</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.024025</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163642</td>\n",
       "      <td>-0.169456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>-0.216057</td>\n",
       "      <td>-0.125939</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.269818</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>54751137</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136277</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.166832</td>\n",
       "      <td>-0.115508</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.157351</td>\n",
       "      <td>-0.163254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.049041</td>\n",
       "      <td>-0.038193</td>\n",
       "      <td>-0.011377</td>\n",
       "      <td>-1.760926</td>\n",
       "      <td>-1.760984</td>\n",
       "      <td>67576672</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136278</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.167233</td>\n",
       "      <td>-0.115086</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.157761</td>\n",
       "      <td>-0.163658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.084674</td>\n",
       "      <td>-0.140597</td>\n",
       "      <td>1.519700</td>\n",
       "      <td>1.521399</td>\n",
       "      <td>69767012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136279</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.172509</td>\n",
       "      <td>-0.120473</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163159</td>\n",
       "      <td>-0.168980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.084674</td>\n",
       "      <td>-0.140597</td>\n",
       "      <td>-1.760926</td>\n",
       "      <td>-1.760984</td>\n",
       "      <td>70384401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136280</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.172805</td>\n",
       "      <td>-0.112290</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163461</td>\n",
       "      <td>-0.169278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>67603017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203752</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.159293</td>\n",
       "      <td>-0.037276</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>0.035526</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.149635</td>\n",
       "      <td>-0.155646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231244</td>\n",
       "      <td>-0.388216</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>1.931078</td>\n",
       "      <td>3.168259</td>\n",
       "      <td>3.707301</td>\n",
       "      <td>-1.390548</td>\n",
       "      <td>-1.214035</td>\n",
       "      <td>80329479</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203754</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.172962</td>\n",
       "      <td>-0.126566</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163622</td>\n",
       "      <td>-0.169437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>10.914916</td>\n",
       "      <td>1.700384</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>7.914145</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>158406298</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203759</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.170412</td>\n",
       "      <td>-0.078164</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>0.054722</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163631</td>\n",
       "      <td>-0.167106</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>158375075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203763</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.093732</td>\n",
       "      <td>-0.116160</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.082559</td>\n",
       "      <td>-0.089510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>147478192</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203766</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.172014</td>\n",
       "      <td>-0.078182</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>0.054722</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163626</td>\n",
       "      <td>-0.168778</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>158375402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16670 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1         2         3         4         5         6         7  \\\n",
       "136276  35 -0.172982 -0.055242 -1.201369 -0.121970 -0.024025 -0.113002   \n",
       "136277  35 -0.166832 -0.115508  1.018602 -0.121970 -0.043875 -0.113002   \n",
       "136278  35 -0.167233 -0.115086  1.018602 -0.121970 -0.043875 -0.113002   \n",
       "136279  35 -0.172509 -0.120473 -0.091383 -0.121970 -0.043875 -0.113002   \n",
       "136280  35 -0.172805 -0.112290  1.018602 -0.121970 -0.063725 -0.113002   \n",
       "...     ..       ...       ...       ...       ...       ...       ...   \n",
       "203752  49 -0.159293 -0.037276  1.018602 -0.121970  0.035526 -0.113002   \n",
       "203754  49 -0.172962 -0.126566  1.018602 -0.121970 -0.063725 -0.113002   \n",
       "203759  49 -0.170412 -0.078164  1.018602  0.028105 -0.043875  0.054722   \n",
       "203763  49 -0.093732 -0.116160  1.018602 -0.121970 -0.043875 -0.113002   \n",
       "203766  49 -0.172014 -0.078182  1.018602  0.028105 -0.043875  0.054722   \n",
       "\n",
       "               8         9        10  ...       159       160        161  \\\n",
       "136276 -0.061584 -0.163642 -0.169456  ...  0.241128  0.241406  -0.216057   \n",
       "136277 -0.061584 -0.157351 -0.163254  ... -0.979074 -0.978556   0.018279   \n",
       "136278 -0.061584 -0.157761 -0.163658  ... -0.979074 -0.978556  -0.098889   \n",
       "136279 -0.061584 -0.163159 -0.168980  ... -0.979074 -0.978556  -0.098889   \n",
       "136280 -0.061584 -0.163461 -0.169278  ...  0.241128  0.241406   0.018279   \n",
       "...          ...       ...       ...  ...       ...       ...        ...   \n",
       "203752 -0.061584 -0.149635 -0.155646  ...  0.231244 -0.388216  -0.098889   \n",
       "203754 -0.061584 -0.163622 -0.169437  ...  0.241128  0.241406  10.914916   \n",
       "203759 -0.061584 -0.163631 -0.167106  ...  1.461330  1.461369   0.018279   \n",
       "203763 -0.061584 -0.082559 -0.089510  ...  0.241128  0.241406   0.018279   \n",
       "203766 -0.061584 -0.163626 -0.168778  ...  1.461330  1.461369   0.018279   \n",
       "\n",
       "             162       163       164       165       166       txId  class  \n",
       "136276 -0.125939 -0.131155 -0.269818 -0.120613 -0.119792   54751137      2  \n",
       "136277 -0.049041 -0.038193 -0.011377 -1.760926 -1.760984   67576672      2  \n",
       "136278 -0.087490 -0.084674 -0.140597  1.519700  1.521399   69767012      2  \n",
       "136279 -0.087490 -0.084674 -0.140597 -1.760926 -1.760984   70384401      1  \n",
       "136280 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792   67603017      1  \n",
       "...          ...       ...       ...       ...       ...        ...    ...  \n",
       "203752  1.931078  3.168259  3.707301 -1.390548 -1.214035   80329479      2  \n",
       "203754  1.700384 -0.131155  7.914145 -0.120613 -0.119792  158406298      2  \n",
       "203759 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  158375075      1  \n",
       "203763 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  147478192      2  \n",
       "203766 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792  158375402      1  \n",
       "\n",
       "[16670 rows x 168 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take time step from 1 to 34 as train data\n",
    "df_train = df_merge[df_merge[1] <= 34]\n",
    "# take rest as test data\n",
    "df_test = df_merge[df_merge[1] > 34]\n",
    "display(df_train)\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape:  (29894, 94)\n",
      "Train labels shape:  (29894,)\n",
      "Test features shape:  (16670, 94)\n",
      "Test labels shape:  (16670,)\n"
     ]
    }
   ],
   "source": [
    "num_features = 94\n",
    "\n",
    "# split train and test features\n",
    "train_features = df_train.iloc[:, 1:num_features+1].values\n",
    "test_features = df_test.iloc[:, 1:num_features+1].values\n",
    "\n",
    "# split train and test labels, label is last column\n",
    "train_labels = df_train.iloc[:, -1].values\n",
    "test_labels = df_test.iloc[:, -1].values\n",
    "\n",
    "\n",
    "print(\"Train features shape: \", train_features.shape)\n",
    "print(\"Train labels shape: \", train_labels.shape)\n",
    "\n",
    "print(\"Test features shape: \", test_features.shape)\n",
    "print(\"Test labels shape: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 234355])\n"
     ]
    }
   ],
   "source": [
    "edges = df_edges.copy()\n",
    "edges = edges.astype(int)\n",
    "\n",
    "# not used\n",
    "all_edge_index = np.array(edges.values).T\n",
    "all_edge_index = torch.tensor(all_edge_index, dtype=torch.long).contiguous()\n",
    "print(all_edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 22898])\n"
     ]
    }
   ],
   "source": [
    "# maske with same time step\n",
    "train_edge_mask = (edges[\"txId1\"].isin(df_train[\"txId\"].values)) & (edges[\"txId2\"].isin(df_train[\"txId\"].values))\n",
    "train_edge_index = edges[[\"txId1\", \"txId2\"]][train_edge_mask.values]\n",
    "\n",
    "train_nodes = df_train[\"txId\"].values\n",
    "map_train_id = {j:i for i,j in enumerate(train_nodes)}\n",
    "\n",
    "train_edge_index[\"txId1\"] = train_edge_index[\"txId1\"].map(map_train_id)\n",
    "train_edge_index[\"txId2\"] = train_edge_index[\"txId2\"].map(map_train_id)\n",
    "\n",
    "train_edge_index = np.array(train_edge_index.values).T\n",
    "train_edge_index = torch.tensor(train_edge_index, dtype=torch.long).contiguous()\n",
    "\n",
    "print(train_edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13726])\n"
     ]
    }
   ],
   "source": [
    "# edge mask for test data\n",
    "test_edge_mask = (edges[\"txId1\"].isin(df_test[\"txId\"].values)) & (edges[\"txId2\"].isin(df_test[\"txId\"].values))\n",
    "test_edge_index = edges[[\"txId1\", \"txId2\"]][test_edge_mask.values]\n",
    "\n",
    "# map test edge index value and test node index\n",
    "test_nodes = df_test[\"txId\"].values\n",
    "map_test_nodes = {j:i for i,j in enumerate(test_nodes)}\n",
    "\n",
    "test_edge_index[\"txId1\"] = test_edge_index[\"txId1\"].map(map_test_nodes)\n",
    "test_edge_index[\"txId2\"] = test_edge_index[\"txId2\"].map(map_test_nodes)\n",
    "\n",
    "test_edge_index = np.array(test_edge_index.values).T\n",
    "test_edge_index = torch.tensor(test_edge_index, dtype=torch.long).contiguous()\n",
    "print(test_edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[29894, 94], edge_index=[2, 22898], y=[29894])\n",
      "Data(x=[16670, 94], edge_index=[2, 13726], y=[16670])\n"
     ]
    }
   ],
   "source": [
    "# construct graph train data and test data\n",
    "train_graph = Data(x=torch.tensor(train_features, dtype=torch.double), edge_index=train_edge_index, y=torch.tensor(train_labels, dtype=torch.long))\n",
    "test_graph = Data(x=torch.tensor(test_features, dtype=torch.double), edge_index=test_edge_index, y=torch.tensor(test_labels, dtype=torch.long))\n",
    "print(train_graph)\n",
    "print(test_graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCN Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-layer GCN\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, hidden_channels=128):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "        self.dropout = Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    loss = F.cross_entropy(logits, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        y_cpu = data.y.cpu() \n",
    "        pred_cpu = pred.cpu() \n",
    "        acc = accuracy_score(y_cpu, pred_cpu)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Loss: 0.2780, Acc: 0.8591: 100%|██████████| 200/200 [00:01<00:00, 112.87it/s]\n"
     ]
    }
   ],
   "source": [
    "model = GCN(num_features, 3).to(device)\n",
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "pbr = tqdm(range(1, num_epochs+1))\n",
    "for epoch in pbr:\n",
    "    model = model.double()\n",
    "    loss = train(model, train_graph, optimizer)\n",
    "    acc = test(model, test_graph)\n",
    "    pbr.set_description(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Acc: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8591\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "test_acc = test(model, test_graph.to(device))\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
