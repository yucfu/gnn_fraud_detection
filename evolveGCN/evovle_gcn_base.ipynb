{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import Linear, LayerNorm, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import ChebConv, NNConv, DeepGCNLayer, GATConv, DenseGCNConv, GCNConv, GraphConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric_temporal.nn.recurrent import EvolveGCNO\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ref: https://medium.com/stanford-cs224w/fraud-detection-with-gat-edac49bda1a0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[203769, 166], edge_index=[2, 234355], edge_attr=[234355], y=[203769], train_idx=Int64Index([     3,      9,     10,     11,     16,     17,     25,     27,\n",
       "                29,     30,\n",
       "            ...\n",
       "            136232, 136233, 136234, 136236, 136239, 136241, 136243, 136249,\n",
       "            136250, 136258],\n",
       "           dtype='int64', length=29894), test_idx=Int64Index([136276, 136277, 136278, 136279, 136280, 136282, 136285, 136287,\n",
       "            136288, 136291,\n",
       "            ...\n",
       "            203727, 203730, 203736, 203740, 203750, 203752, 203754, 203759,\n",
       "            203763, 203766],\n",
       "           dtype='int64', length=16670))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data \n",
    "df_features = pd.read_csv('../data/elliptic_txs_features.csv', header=None)\n",
    "df_edges = pd.read_csv(\"../data/elliptic_txs_edgelist.csv\")\n",
    "df_classes =  pd.read_csv(\"../data/elliptic_txs_classes.csv\")\n",
    "\n",
    "df_classes['class'] = df_classes['class'].map({'unknown': 2, '1':1, '2':0})\n",
    "\n",
    "# merging dataframes\n",
    "df_merge = df_features.merge(df_classes, how='left', right_on=\"txId\", left_on=0)\n",
    "df_merge.drop(0, axis=1, inplace=True)\n",
    "\n",
    "# check if there are duplicate txId\n",
    "# print(\"Number of duplicate txId: \", df_merge.duplicated(subset=['txId']).sum())\n",
    "\n",
    "# rename column 0 to time_step\n",
    "df_merge.rename(columns={1: 'time_step'}, inplace=True)\n",
    "# display(df_merge.head())\n",
    "# display(df_edges.shape)\n",
    "edges = df_edges.copy()\n",
    "\n",
    "# Setup trans ID to node ID mapping\n",
    "nodes = df_merge['txId'].values\n",
    "map_id = {j:i for i,j in enumerate(nodes)} # mapping nodes to indexes\n",
    "\n",
    "# Map transction IDs to node Ids\n",
    "edges.txId1 = edges.txId1.map(map_id) #get nodes idx1 from edges list and filtered data\n",
    "edges.txId2 = edges.txId2.map(map_id)\n",
    "edges = edges.astype(int)\n",
    "\n",
    "# Reformat and convert to tensor\n",
    "edge_index = np.array(edges.values).T \n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).contiguous()\n",
    "\n",
    "# print(\"shape of edge index is {}\".format(edge_index.shape))\n",
    "node_features = df_merge.drop(['txId'], axis=1).copy()\n",
    "# print(\"unique=\",node_features[\"class\"].unique())\n",
    "\n",
    "# Retain known vs unknown IDs\n",
    "all_classified_idx = node_features['class'].loc[node_features['class']!=2].index # filter on known labels\n",
    "all_unclassified_idx = node_features['class'].loc[node_features['class']==2].index\n",
    "all_classified_illicit_idx = node_features['class'].loc[node_features['class']==1].index # filter on illicit labels\n",
    "all_classified_licit_idx = node_features['class'].loc[node_features['class']==0].index # filter on licit labels\n",
    "\n",
    "# node_features = node_features.drop(columns=[0, 1, 'class'])\n",
    "# display(node_features.head())\n",
    "train_classified_idx = node_features.loc[(node_features['time_step'] <= 34) & (node_features['class'] != 2)].index\n",
    "test_classified_idx = node_features.loc[(node_features['time_step'] > 34) & (node_features['class'] != 2)].index\n",
    "# print(\"train_classified_idx.shape=\",train_classified_idx.shape)\n",
    "# print(\"test_classified_idx.shape=\",test_classified_idx.shape)\n",
    "# node_features.drop(columns=['time_step'], inplace=True)\n",
    "node_features.drop(columns=['class'], inplace=True)\n",
    "\n",
    "# Convert to tensor\n",
    "node_features_t = torch.tensor(np.array(node_features.values, dtype=np.double), dtype=torch.double)\n",
    "# Define labels\n",
    "labels = df_merge['class'].values\n",
    "\n",
    "#create weights tensor with same shape of edge_index\n",
    "weights = torch.tensor([1]* edge_index.shape[1] , dtype=torch.double) \n",
    "\n",
    "# Do train test split on classified_ids\n",
    "train_idx = train_classified_idx\n",
    "test_idx = test_classified_idx\n",
    "\n",
    "# Create pyG dataset\n",
    "data_graph = Data(x=node_features_t.float(), edge_index=edge_index, edge_attr=weights, \n",
    "                               y=torch.tensor(labels, dtype=torch.long))\n",
    "\n",
    "# Add in the train and valid idx\n",
    "data_graph.train_idx = train_idx\n",
    "data_graph.test_idx = test_idx\n",
    "data_graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EvolveGCN Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolveGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, num_classes):\n",
    "        super(EvolveGCN, self).__init__()\n",
    "        self.node_features = node_features\n",
    "        self.num_classes = num_classes\n",
    "        self.base_model = EvolveGCNO(self.node_features)\n",
    "        self.fc = torch.nn.Linear(self.node_features, self.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = self.base_model(data.x, data.edge_index, data.edge_attr)\n",
    "        out = out.float() \n",
    "        out = self.fc(out)  \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    # out = out.reshape((data.x.shape[0]))\n",
    "    # TODO :use weighted cross entropy loss\n",
    "    loss = F.cross_entropy(out[data.train_idx], data.y[data.train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        pred_scores = out[data.test_idx]\n",
    "        pred = torch.argmax(pred_scores, dim=1)\n",
    "        y = data.y[data.test_idx]\n",
    "        acc = accuracy_score(y.cpu(), pred.cpu())\n",
    "        f1 = f1_score(y.cpu(), pred.cpu())\n",
    "        precision = precision_score(y.cpu(), pred.cpu())\n",
    "        recall = recall_score(y.cpu(), pred.cpu())\n",
    "        roc = roc_auc_score(y.cpu(), pred.cpu())\n",
    "        return acc, f1, precision, recall, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features= 166\n"
     ]
    }
   ],
   "source": [
    "num_features = data_graph.num_node_features\n",
    "print(\"num_features=\",num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 2.3002, Accuracy: 0.0870, F1: 0.1231, Precision: 0.0656, Recall: 0.9861, ROC: 0.5054\n",
      "Epoch: 010, Loss: 0.6439, Accuracy: 0.9350, F1: 0.0000, Precision: 0.0000, Recall: 0.0000, ROC: 0.5000\n",
      "Epoch: 020, Loss: 0.3534, Accuracy: 0.7423, F1: 0.2679, Precision: 0.1643, Recall: 0.7258, ROC: 0.7346\n",
      "Epoch: 030, Loss: 0.3096, Accuracy: 0.9342, F1: 0.0000, Precision: 0.0000, Recall: 0.0000, ROC: 0.4996\n",
      "Epoch: 040, Loss: 0.2834, Accuracy: 0.8406, F1: 0.2567, Precision: 0.1841, Recall: 0.4238, ROC: 0.6467\n",
      "Epoch: 050, Loss: 0.2654, Accuracy: 0.9268, F1: 0.0145, Precision: 0.0577, Recall: 0.0083, ROC: 0.4994\n",
      "Epoch: 060, Loss: 0.2546, Accuracy: 0.8652, F1: 0.2905, Precision: 0.2207, Recall: 0.4247, ROC: 0.6603\n",
      "Epoch: 070, Loss: 0.2451, Accuracy: 0.8929, F1: 0.2680, Precision: 0.2410, Recall: 0.3019, ROC: 0.6179\n",
      "Epoch: 080, Loss: 0.2383, Accuracy: 0.8640, F1: 0.2940, Precision: 0.2218, Recall: 0.4358, ROC: 0.6648\n",
      "Epoch: 090, Loss: 0.2329, Accuracy: 0.8419, F1: 0.3042, Precision: 0.2130, Recall: 0.5319, ROC: 0.6977\n",
      "Epoch: 100, Loss: 0.2286, Accuracy: 0.8440, F1: 0.3058, Precision: 0.2151, Recall: 0.5291, ROC: 0.6975\n",
      "Epoch: 110, Loss: 0.2250, Accuracy: 0.8397, F1: 0.3091, Precision: 0.2146, Recall: 0.5522, ROC: 0.7059\n",
      "Epoch: 120, Loss: 0.2220, Accuracy: 0.8307, F1: 0.3056, Precision: 0.2083, Recall: 0.5734, ROC: 0.7110\n",
      "Epoch: 130, Loss: 0.2194, Accuracy: 0.8242, F1: 0.3010, Precision: 0.2029, Recall: 0.5826, ROC: 0.7118\n",
      "Epoch: 140, Loss: 0.2172, Accuracy: 0.8209, F1: 0.3017, Precision: 0.2020, Recall: 0.5956, ROC: 0.7160\n",
      "Epoch: 150, Loss: 0.2152, Accuracy: 0.8188, F1: 0.3022, Precision: 0.2015, Recall: 0.6039, ROC: 0.7188\n",
      "Epoch: 160, Loss: 0.2135, Accuracy: 0.8179, F1: 0.3053, Precision: 0.2030, Recall: 0.6159, ROC: 0.7239\n",
      "Epoch: 170, Loss: 0.2120, Accuracy: 0.8164, F1: 0.3045, Precision: 0.2019, Recall: 0.6187, ROC: 0.7244\n",
      "Epoch: 180, Loss: 0.2106, Accuracy: 0.8153, F1: 0.3051, Precision: 0.2019, Recall: 0.6242, ROC: 0.7264\n",
      "Epoch: 190, Loss: 0.2094, Accuracy: 0.8142, F1: 0.3054, Precision: 0.2017, Recall: 0.6288, ROC: 0.7280\n",
      "Epoch: 200, Loss: 0.2082, Accuracy: 0.8133, F1: 0.3056, Precision: 0.2015, Recall: 0.6325, ROC: 0.7292\n"
     ]
    }
   ],
   "source": [
    "model = EvolveGCN(num_features, 2).to(device)\n",
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs+1):\n",
    "    loss = train(model, data_graph, optimizer)\n",
    "    acc, f1, precision, recall, roc = test(model, data_graph)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Accuracy: {acc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, ROC: {roc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8443, F1: 0.3317, Precision: 0.2300, Recall: 0.5946, ROC: 0.7282\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "acc, f1, precision, recall, roc = test(model, data_graph)\n",
    "print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, ROC: {roc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
