{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import Linear, LayerNorm, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import ChebConv, NNConv, DeepGCNLayer, GATConv, DenseGCNConv, GCNConv, GraphConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric_temporal.nn.recurrent import EvolveGCNO\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ref: https://medium.com/stanford-cs224w/fraud-detection-with-gat-edac49bda1a0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[203769, 166], edge_index=[2, 234355], edge_attr=[234355], y=[203769], train_idx=Int64Index([     3,      9,     10,     11,     16,     17,     25,     27,\n",
       "                29,     30,\n",
       "            ...\n",
       "            136232, 136233, 136234, 136236, 136239, 136241, 136243, 136249,\n",
       "            136250, 136258],\n",
       "           dtype='int64', length=29894), test_idx=Int64Index([136276, 136277, 136278, 136279, 136280, 136282, 136285, 136287,\n",
       "            136288, 136291,\n",
       "            ...\n",
       "            203727, 203730, 203736, 203740, 203750, 203752, 203754, 203759,\n",
       "            203763, 203766],\n",
       "           dtype='int64', length=16670))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data \n",
    "df_features = pd.read_csv('../data/elliptic_txs_features.csv', header=None)\n",
    "df_edges = pd.read_csv(\"../data/elliptic_txs_edgelist.csv\")\n",
    "df_classes =  pd.read_csv(\"../data/elliptic_txs_classes.csv\")\n",
    "\n",
    "df_classes['class'] = df_classes['class'].map({'unknown': 2, '1':1, '2':0})\n",
    "\n",
    "# merging dataframes\n",
    "df_merge = df_features.merge(df_classes, how='left', right_on=\"txId\", left_on=0)\n",
    "df_merge.drop(0, axis=1, inplace=True)\n",
    "\n",
    "# check if there are duplicate txId\n",
    "# print(\"Number of duplicate txId: \", df_merge.duplicated(subset=['txId']).sum())\n",
    "\n",
    "# rename column 0 to time_step\n",
    "df_merge.rename(columns={1: 'time_step'}, inplace=True)\n",
    "# display(df_merge.head())\n",
    "# display(df_edges.shape)\n",
    "edges = df_edges.copy()\n",
    "\n",
    "# Setup trans ID to node ID mapping\n",
    "nodes = df_merge['txId'].values\n",
    "map_id = {j:i for i,j in enumerate(nodes)} # mapping nodes to indexes\n",
    "\n",
    "# Map transction IDs to node Ids\n",
    "edges.txId1 = edges.txId1.map(map_id) #get nodes idx1 from edges list and filtered data\n",
    "edges.txId2 = edges.txId2.map(map_id)\n",
    "edges = edges.astype(int)\n",
    "\n",
    "# Reformat and convert to tensor\n",
    "edge_index = np.array(edges.values).T \n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).contiguous()\n",
    "\n",
    "# print(\"shape of edge index is {}\".format(edge_index.shape))\n",
    "node_features = df_merge.drop(['txId'], axis=1).copy()\n",
    "# print(\"unique=\",node_features[\"class\"].unique())\n",
    "\n",
    "# Retain known vs unknown IDs\n",
    "all_classified_idx = node_features['class'].loc[node_features['class']!=2].index # filter on known labels\n",
    "all_unclassified_idx = node_features['class'].loc[node_features['class']==2].index\n",
    "all_classified_illicit_idx = node_features['class'].loc[node_features['class']==1].index # filter on illicit labels\n",
    "all_classified_licit_idx = node_features['class'].loc[node_features['class']==0].index # filter on licit labels\n",
    "\n",
    "# node_features = node_features.drop(columns=[0, 1, 'class'])\n",
    "# display(node_features.head())\n",
    "train_classified_idx = node_features.loc[(node_features['time_step'] <= 34) & (node_features['class'] != 2)].index\n",
    "test_classified_idx = node_features.loc[(node_features['time_step'] > 34) & (node_features['class'] != 2)].index\n",
    "# print(\"train_classified_idx.shape=\",train_classified_idx.shape)\n",
    "# print(\"test_classified_idx.shape=\",test_classified_idx.shape)\n",
    "# node_features.drop(columns=['time_step'], inplace=True)\n",
    "node_features.drop(columns=['class'], inplace=True)\n",
    "\n",
    "# Convert to tensor\n",
    "node_features_t = torch.tensor(np.array(node_features.values, dtype=np.double), dtype=torch.double)\n",
    "# Define labels\n",
    "labels = df_merge['class'].values\n",
    "\n",
    "#create weights tensor with same shape of edge_index\n",
    "weights = torch.tensor([1]* edge_index.shape[1] , dtype=torch.double) \n",
    "\n",
    "# Do train test split on classified_ids\n",
    "train_idx = train_classified_idx\n",
    "test_idx = test_classified_idx\n",
    "\n",
    "# Create pyG dataset\n",
    "data_graph = Data(x=node_features_t.float(), edge_index=edge_index, edge_attr=weights, \n",
    "                               y=torch.tensor(labels, dtype=torch.long))\n",
    "\n",
    "# Add in the train and valid idx\n",
    "data_graph.train_idx = train_idx\n",
    "data_graph.test_idx = test_idx\n",
    "data_graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EvolveGCN Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvolveGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, num_classes):\n",
    "        super(EvolveGCN, self).__init__()\n",
    "        self.node_features = node_features\n",
    "        self.num_classes = num_classes\n",
    "        self.base_model = EvolveGCNO(self.node_features)\n",
    "        self.fc = torch.nn.Linear(self.node_features, self.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = self.base_model(data.x, data.edge_index, data.edge_attr)\n",
    "        out = out.float() \n",
    "        out = self.fc(out)  \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_WEIGTHS = [0.7,0.3]\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    # out = out.reshape((data.x.shape[0]))\n",
    "    weights = torch.tensor(CLASS_WEIGTHS, dtype=torch.float).to(device)\n",
    "    loss = F.cross_entropy(out[data.train_idx], data.y[data.train_idx], weight=weights)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        pred_scores = out[data.test_idx]\n",
    "        pred = torch.argmax(pred_scores, dim=1)\n",
    "        y = data.y[data.test_idx]\n",
    "        acc = accuracy_score(y.cpu(), pred.cpu())\n",
    "        f1 = f1_score(y.cpu(), pred.cpu())\n",
    "        precision = precision_score(y.cpu(), pred.cpu())\n",
    "        recall = recall_score(y.cpu(), pred.cpu())\n",
    "        roc = roc_auc_score(y.cpu(), pred.cpu())\n",
    "        return acc, f1, precision, recall, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features= 166\n"
     ]
    }
   ],
   "source": [
    "num_features = data_graph.num_node_features\n",
    "print(\"num_features=\",num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 1.2703, Accuracy: 0.9075, F1: 0.1259, Precision: 0.1630, Recall: 0.1025, ROC: 0.5330\n",
      "Epoch: 010, Loss: 0.3909, Accuracy: 0.9349, F1: 0.0000, Precision: 0.0000, Recall: 0.0000, ROC: 0.4999\n",
      "Epoch: 020, Loss: 0.1997, Accuracy: 0.9348, F1: 0.0000, Precision: 0.0000, Recall: 0.0000, ROC: 0.4999\n",
      "Epoch: 030, Loss: 0.1850, Accuracy: 0.9349, F1: 0.0000, Precision: 0.0000, Recall: 0.0000, ROC: 0.4999\n",
      "Epoch: 040, Loss: 0.1671, Accuracy: 0.9281, F1: 0.0164, Precision: 0.0741, Recall: 0.0092, ROC: 0.5006\n",
      "Epoch: 050, Loss: 0.1617, Accuracy: 0.9347, F1: 0.0000, Precision: 0.0000, Recall: 0.0000, ROC: 0.4998\n",
      "Epoch: 060, Loss: 0.1554, Accuracy: 0.9232, F1: 0.0560, Precision: 0.1387, Recall: 0.0351, ROC: 0.5100\n",
      "Epoch: 070, Loss: 0.1513, Accuracy: 0.9215, F1: 0.0814, Precision: 0.1696, Recall: 0.0536, ROC: 0.5177\n",
      "Epoch: 080, Loss: 0.1483, Accuracy: 0.9218, F1: 0.0646, Precision: 0.1452, Recall: 0.0416, ROC: 0.5123\n",
      "Epoch: 090, Loss: 0.1458, Accuracy: 0.9128, F1: 0.1199, Precision: 0.1743, Recall: 0.0914, ROC: 0.5307\n",
      "Epoch: 100, Loss: 0.1439, Accuracy: 0.9055, F1: 0.1740, Precision: 0.2012, Recall: 0.1533, ROC: 0.5555\n",
      "Epoch: 110, Loss: 0.1422, Accuracy: 0.9041, F1: 0.2151, Precision: 0.2298, Recall: 0.2022, ROC: 0.5776\n",
      "Epoch: 120, Loss: 0.1408, Accuracy: 0.9023, F1: 0.2305, Precision: 0.2360, Recall: 0.2253, ROC: 0.5873\n",
      "Epoch: 130, Loss: 0.1396, Accuracy: 0.9014, F1: 0.2596, Precision: 0.2535, Recall: 0.2659, ROC: 0.6058\n",
      "Epoch: 140, Loss: 0.1385, Accuracy: 0.9010, F1: 0.2862, Precision: 0.2691, Recall: 0.3056, ROC: 0.6240\n",
      "Epoch: 150, Loss: 0.1376, Accuracy: 0.9001, F1: 0.3012, Precision: 0.2759, Recall: 0.3315, ROC: 0.6355\n",
      "Epoch: 160, Loss: 0.1367, Accuracy: 0.8993, F1: 0.3129, Precision: 0.2811, Recall: 0.3527, ROC: 0.6450\n",
      "Epoch: 170, Loss: 0.1360, Accuracy: 0.8983, F1: 0.3174, Precision: 0.2814, Recall: 0.3638, ROC: 0.6496\n",
      "Epoch: 180, Loss: 0.1352, Accuracy: 0.8977, F1: 0.3198, Precision: 0.2814, Recall: 0.3703, ROC: 0.6523\n",
      "Epoch: 190, Loss: 0.1346, Accuracy: 0.8968, F1: 0.3207, Precision: 0.2802, Recall: 0.3749, ROC: 0.6540\n",
      "Epoch: 200, Loss: 0.1339, Accuracy: 0.8968, F1: 0.3239, Precision: 0.2820, Recall: 0.3804, ROC: 0.6566\n",
      "Epoch: 210, Loss: 0.1333, Accuracy: 0.8967, F1: 0.3263, Precision: 0.2831, Recall: 0.3850, ROC: 0.6586\n",
      "Epoch: 220, Loss: 0.1328, Accuracy: 0.8962, F1: 0.3289, Precision: 0.2836, Recall: 0.3915, ROC: 0.6614\n",
      "Epoch: 230, Loss: 0.1322, Accuracy: 0.8966, F1: 0.3340, Precision: 0.2872, Recall: 0.3989, ROC: 0.6651\n",
      "Epoch: 240, Loss: 0.1316, Accuracy: 0.8969, F1: 0.3382, Precision: 0.2902, Recall: 0.4054, ROC: 0.6682\n",
      "Epoch: 250, Loss: 0.1311, Accuracy: 0.8971, F1: 0.3391, Precision: 0.2910, Recall: 0.4063, ROC: 0.6688\n",
      "Epoch: 260, Loss: 0.1306, Accuracy: 0.8975, F1: 0.3424, Precision: 0.2935, Recall: 0.4109, ROC: 0.6711\n",
      "Epoch: 270, Loss: 0.1301, Accuracy: 0.8978, F1: 0.3442, Precision: 0.2952, Recall: 0.4127, ROC: 0.6721\n",
      "Epoch: 280, Loss: 0.1296, Accuracy: 0.8980, F1: 0.3460, Precision: 0.2964, Recall: 0.4155, ROC: 0.6735\n",
      "Epoch: 290, Loss: 0.1291, Accuracy: 0.8980, F1: 0.3472, Precision: 0.2972, Recall: 0.4174, ROC: 0.6744\n",
      "Epoch: 300, Loss: 0.1286, Accuracy: 0.8985, F1: 0.3527, Precision: 0.3011, Recall: 0.4257, ROC: 0.6785\n",
      "Epoch: 310, Loss: 0.1281, Accuracy: 0.8987, F1: 0.3546, Precision: 0.3025, Recall: 0.4284, ROC: 0.6799\n",
      "Epoch: 320, Loss: 0.1277, Accuracy: 0.8990, F1: 0.3558, Precision: 0.3037, Recall: 0.4294, ROC: 0.6805\n",
      "Epoch: 330, Loss: 0.1272, Accuracy: 0.8991, F1: 0.3595, Precision: 0.3059, Recall: 0.4358, ROC: 0.6836\n",
      "Epoch: 340, Loss: 0.1268, Accuracy: 0.8986, F1: 0.3583, Precision: 0.3041, Recall: 0.4358, ROC: 0.6833\n",
      "Epoch: 350, Loss: 0.1263, Accuracy: 0.8987, F1: 0.3601, Precision: 0.3055, Recall: 0.4386, ROC: 0.6847\n",
      "Epoch: 360, Loss: 0.1259, Accuracy: 0.8988, F1: 0.3612, Precision: 0.3062, Recall: 0.4404, ROC: 0.6855\n",
      "Epoch: 370, Loss: 0.1255, Accuracy: 0.8990, F1: 0.3632, Precision: 0.3077, Recall: 0.4432, ROC: 0.6870\n",
      "Epoch: 380, Loss: 0.1250, Accuracy: 0.8993, F1: 0.3681, Precision: 0.3107, Recall: 0.4515, ROC: 0.6910\n",
      "Epoch: 390, Loss: 0.1246, Accuracy: 0.8993, F1: 0.3701, Precision: 0.3118, Recall: 0.4552, ROC: 0.6927\n",
      "Epoch: 400, Loss: 0.1242, Accuracy: 0.8999, F1: 0.3751, Precision: 0.3155, Recall: 0.4626, ROC: 0.6964\n",
      "Epoch: 410, Loss: 0.1237, Accuracy: 0.8997, F1: 0.3761, Precision: 0.3156, Recall: 0.4654, ROC: 0.6976\n",
      "Epoch: 420, Loss: 0.1233, Accuracy: 0.9002, F1: 0.3796, Precision: 0.3183, Recall: 0.4700, ROC: 0.7000\n",
      "Epoch: 430, Loss: 0.1229, Accuracy: 0.9005, F1: 0.3823, Precision: 0.3204, Recall: 0.4737, ROC: 0.7019\n",
      "Epoch: 440, Loss: 0.1224, Accuracy: 0.9009, F1: 0.3863, Precision: 0.3232, Recall: 0.4801, ROC: 0.7051\n",
      "Epoch: 450, Loss: 0.1220, Accuracy: 0.9013, F1: 0.3890, Precision: 0.3253, Recall: 0.4838, ROC: 0.7071\n",
      "Epoch: 460, Loss: 0.1215, Accuracy: 0.9014, F1: 0.3904, Precision: 0.3263, Recall: 0.4857, ROC: 0.7080\n",
      "Epoch: 470, Loss: 0.1211, Accuracy: 0.9019, F1: 0.3911, Precision: 0.3277, Recall: 0.4848, ROC: 0.7078\n",
      "Epoch: 480, Loss: 0.1206, Accuracy: 0.9020, F1: 0.3918, Precision: 0.3283, Recall: 0.4857, ROC: 0.7083\n",
      "Epoch: 490, Loss: 0.1202, Accuracy: 0.9022, F1: 0.3922, Precision: 0.3290, Recall: 0.4857, ROC: 0.7084\n",
      "Epoch: 500, Loss: 0.1198, Accuracy: 0.9022, F1: 0.3941, Precision: 0.3298, Recall: 0.4894, ROC: 0.7101\n"
     ]
    }
   ],
   "source": [
    "model = EvolveGCN(num_features, 2).to(device)\n",
    "num_epochs = 500\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs+1):\n",
    "    loss = train(model, data_graph, optimizer)\n",
    "    acc, f1, precision, recall, roc = test(model, data_graph)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Accuracy: {acc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, ROC: {roc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9022, F1: 0.3941, Precision: 0.3298, Recall: 0.4894, ROC: 0.7101\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "acc, f1, precision, recall, roc = test(model, data_graph)\n",
    "print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, ROC: {roc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
