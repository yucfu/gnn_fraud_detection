{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import Linear, LayerNorm, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import ChebConv, NNConv, DeepGCNLayer, GATConv, DenseGCNConv, GCNConv, GraphConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ref: https://www.kaggle.com/code/divyareddyyeruva/elliptic-gcn-pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "df_features = pd.read_csv('data/elliptic_txs_features.csv', header=None)\n",
    "df_edges = pd.read_csv(\"data/elliptic_txs_edgelist.csv\")\n",
    "df_classes =  pd.read_csv(\"data/elliptic_txs_classes.csv\")\n",
    "# map unknown classes to -1\n",
    "df_classes['class'] = df_classes['class'].apply(lambda x: 0 if x == \"unknown\" else int(x))\n",
    "\n",
    "# merging dataframes\n",
    "df_merge = df_features.merge(df_classes, how='left', right_on=\"txId\", left_on=0)\n",
    "display(df_merge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take time step from 1 to 34 as train data\n",
    "df_train = df_merge[df_merge[1] <= 34]\n",
    "# take rest as test data\n",
    "df_test = df_merge[df_merge[1] > 34]\n",
    "display(df_train.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 94\n",
    "\n",
    "# split train and test features\n",
    "train_features = df_train.iloc[:, 2:2+num_features].values\n",
    "test_features = df_test.iloc[:, 2:2+num_features].values\n",
    "\n",
    "# split train and test labels\n",
    "train_labels = df_train.iloc[:, -1].values\n",
    "test_labels = df_test.iloc[:, -1].values\n",
    "\n",
    "print(\"Train features shape: \", train_features.shape)\n",
    "print(\"Train labels shape: \", train_labels.shape)\n",
    "\n",
    "print(\"Test features shape: \", test_features.shape)\n",
    "print(\"Test labels shape: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all nodes in data\n",
    "nodes = df_merge[0].values\n",
    "map_id = {j:i for i,j in enumerate(nodes)} # mapping nodes to indexes\n",
    "\n",
    "edges = df_edges.copy()\n",
    "edges.txId1 = edges.txId1.map(map_id)\n",
    "edges.txId2 = edges.txId2.map(map_id)\n",
    "edges = edges.astype(int)\n",
    "\n",
    "edge_index = np.array(edges.values).T\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).contiguous()\n",
    "edge_weight = torch.tensor([1]* edge_index.shape[1] , dtype=torch.double)\n",
    "print(edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes = df_train[0].unique()\n",
    "map_id = {j:i for i,j in enumerate(nodes)}\n",
    "train_idx = [map_id[node_id] for node_id in train_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_mask = edges['txId1'].isin(train_idx) & edges['txId2'].isin(train_idx)\n",
    "train_edge_index = edge_index[:, train_edge_mask]\n",
    "train_edge_weight = edge_weight[train_edge_mask]\n",
    "train_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse mapping for test data\n",
    "test_nodes = df_test[0].unique()\n",
    "map_id = {j:i for i,j in enumerate(nodes)}\n",
    "test_idx = [map_id[node_id] for node_id in test_nodes]\n",
    "\n",
    "test_edge_mask = edges['txId1'].isin(test_idx) & edges['txId2'].isin(test_idx)\n",
    "test_edge_index = edge_index[:, test_edge_mask]\n",
    "test_edge_weight = edge_weight[test_edge_mask]\n",
    "test_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_index = test_edge_index - 136265\n",
    "# new_test_index = new_test_index.long()\n",
    "type(new_test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct graph train data and test data\n",
    "train_graph = Data(x=torch.tensor(train_features, dtype=torch.double), edge_index=train_edge_index, edge_weight=train_edge_weight, y=torch.tensor(train_labels, dtype=torch.long))\n",
    "# train_graph = Data(x=torch.tensor(train_features, dtype=torch.float), edge_index=edge_index, edge_weight=edge_weight, y=torch.tensor(train_labels, dtype=torch.double))\n",
    "test_graph = Data(x=torch.tensor(test_features, dtype=torch.double), edge_index=new_test_index, edge_weight=test_edge_weight, y=torch.tensor(test_labels, dtype=torch.long))\n",
    "print(train_graph)\n",
    "print(test_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "\n",
    "\n",
    "class TransactionGCN(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats, g, device):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(in_feats, hidden_feats,\n",
    "                               allow_zero_in_degree=True)\n",
    "        self.conv2 = GraphConv(hidden_feats, out_feats,\n",
    "                               allow_zero_in_degree=True)\n",
    "        self.lin1 = nn.Linear(in_feats, hidden_feats)\n",
    "        self.lin2 = nn.Linear(hidden_feats, out_feats)\n",
    "\n",
    "        g.ndata['feat'] = torch.nn.init.xavier_uniform_(torch.empty(\n",
    "            g.num_nodes(), g.edata['feat'].shape[1])).to(torch.float32).to(device)\n",
    "        g.ndata['h'] = g.ndata['feat']\n",
    "        g.edata['x'] = g.edata['feat']\n",
    "\n",
    "    def forward(self, g, h, e):\n",
    "        h1 = torch.relu(self.conv1(g, h))\n",
    "        e1 = torch.relu(self.lin1(e))\n",
    "        g.ndata['h'] = h1\n",
    "        g.edata['x'] = e1\n",
    "        g.apply_edges(\n",
    "            lambda edges: {'x': edges.src['h'] + edges.dst['h'] + edges.data['x']})\n",
    "\n",
    "        h2 = self.conv2(g, h1)\n",
    "        e2 = torch.relu(self.lin2(e1))\n",
    "        g.ndata['h'] = h2\n",
    "        g.edata['x'] = e2\n",
    "        g.apply_edges(\n",
    "            lambda edges: {'x': edges.src['h'] + edges.dst['h'] + edges.data['x']})\n",
    "        return g.ndata['h'], g.edata['x']\n",
    "\n",
    "\n",
    "class stagn_2d_model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        time_windows_dim: int,\n",
    "        feat_dim: int,\n",
    "        num_classes: int,\n",
    "        attention_hidden_dim: int,\n",
    "        g: dgl.DGLGraph,\n",
    "        filter_sizes: tuple = (2, 2),\n",
    "        num_filters: int = 64,\n",
    "        in_channels: int = 1,\n",
    "        device=\"cpu\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the STAGN-2d model\n",
    "\n",
    "        Args:\n",
    "        :param time_windows_dim (int): length of time windows\n",
    "        :param feat_dim (int): feature dimension\n",
    "        :param num_classes (int): number of classes\n",
    "        :param attention_hidden_dim (int): attention hidden dimenstion\n",
    "        :param g (dgl.DGLGraph): dgl graph for gcn embeddings\n",
    "        :param filter_sizes (tuple, optional): cnn filter size\n",
    "        :param num_filters (int, optional): number of hidden channels\n",
    "        :param in_channels (int, optional): number of in channels\n",
    "        :param device (str, optional): where to train the model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.time_windows_dim = time_windows_dim\n",
    "        self.feat_dim = feat_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.num_filters = num_filters\n",
    "\n",
    "        self.graph = g.to(device)\n",
    "\n",
    "        # attention layer\n",
    "        self.attention_W = nn.Parameter(torch.Tensor(\n",
    "            self.feat_dim, self.attention_hidden_dim).uniform_(0., 1.))\n",
    "        self.attention_U = nn.Parameter(torch.Tensor(\n",
    "            self.feat_dim, self.attention_hidden_dim).uniform_(0., 1.))\n",
    "        self.attention_V = nn.Parameter(torch.Tensor(\n",
    "            self.attention_hidden_dim, 1).uniform_(0., 1.))\n",
    "\n",
    "        # cnn layer\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=num_filters,\n",
    "            kernel_size=filter_sizes,\n",
    "            padding='same'\n",
    "        )\n",
    "\n",
    "        # FC layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linears1 = nn.Sequential(\n",
    "            nn.LazyLinear(256),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(24),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.linears2 = nn.LazyLinear(self.num_classes)\n",
    "\n",
    "        # gnn for transaction graph\n",
    "        self.gcn = TransactionGCN(\n",
    "            g.edata['feat'].shape[1], 128, 8, g, device)\n",
    "\n",
    "    def attention_layer(\n",
    "        self,\n",
    "        X: torch.Tensor\n",
    "    ):\n",
    "        self.output_att = []\n",
    "        # input_att = torch.split(X, self.time_windows_dim, dim=1)\n",
    "        input_att = torch.split(X, 1, dim=1)  # 第二个参数是split_size!\n",
    "        for index, x_i in enumerate(input_att):\n",
    "            # print(f\"x_i shape: {x_i.shape}\")\n",
    "            x_i = x_i.reshape(-1, self.feat_dim)\n",
    "            c_i = self.attention(x_i, input_att, index)\n",
    "            inp = torch.concat([x_i, c_i], axis=1)\n",
    "            self.output_att.append(inp)\n",
    "\n",
    "        input_conv = torch.reshape(torch.concat(self.output_att, axis=1),\n",
    "                                   [-1, self.time_windows_dim, self.feat_dim*2])\n",
    "\n",
    "        self.input_conv_expanded = torch.unsqueeze(input_conv, 1)\n",
    "\n",
    "        return self.input_conv_expanded\n",
    "\n",
    "    def cnn_layer(\n",
    "        self,\n",
    "        input: torch.Tensor\n",
    "    ):\n",
    "        if len(input.shape) == 3:\n",
    "            self.input_conv_expanded = torch.unsqueeze(input, 1)\n",
    "        elif len(input.shape) == 4:\n",
    "            self.input_conv_expanded = input\n",
    "        else:\n",
    "            print(\"Wrong conv input shape!\")\n",
    "\n",
    "        self.input_conv_expanded = F.relu(self.conv(input))\n",
    "\n",
    "        return self.input_conv_expanded\n",
    "\n",
    "    def attention(self, x_i, x, index):\n",
    "        e_i = []\n",
    "        c_i = []\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            output = x[i]\n",
    "            output = output.reshape(-1, self.feat_dim)\n",
    "            att_hidden = torch.tanh(torch.add(torch.matmul(\n",
    "                x_i, self.attention_W), torch.matmul(output, self.attention_U)))\n",
    "            e_i_j = torch.matmul(att_hidden, self.attention_V)\n",
    "            e_i.append(e_i_j)\n",
    "\n",
    "        e_i = torch.concat(e_i, axis=1)\n",
    "        # print(f\"e_i shape: {e_i.shape}\")\n",
    "        alpha_i = F.softmax(e_i, dim=1)\n",
    "        alpha_i = torch.split(alpha_i, 1, 1)  # !!!\n",
    "\n",
    "        for j, (alpha_i_j, output) in enumerate(zip(alpha_i, x)):\n",
    "            if j == index:\n",
    "                continue\n",
    "            else:\n",
    "                output = output.reshape(-1, self.feat_dim)\n",
    "                c_i_j = torch.multiply(alpha_i_j, output)\n",
    "                c_i.append(c_i_j)\n",
    "\n",
    "        c_i = torch.reshape(torch.concat(c_i, axis=1),\n",
    "                            [-1, self.time_windows_dim-1, self.feat_dim])\n",
    "        c_i = torch.sum(c_i, dim=1)\n",
    "        return c_i\n",
    "\n",
    "    def forward(self, X_nume, g):\n",
    "        # X shape be like: (batch_size, time_windows_dim, feat_dim)\n",
    "        out = self.attention_layer(X_nume)  # all, 1, 8, 10\n",
    "\n",
    "        out = self.cnn_layer(out)  # all, 64, 8, 10\n",
    "        node_embs, edge_embs = self.gcn(g, g.ndata['feat'], g.edata['feat'])\n",
    "\n",
    "        src_nds, dst_nds = g.edges()\n",
    "        src_feat = g.ndata['h'][src_nds]\n",
    "        dst_feat = g.ndata['h'][dst_nds]\n",
    "        # all, 3, embedding_dim\n",
    "        node_feats = torch.stack(\n",
    "            [src_feat, dst_feat, edge_embs], dim=1).view(X_nume.shape[0], -1)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linears1(out)\n",
    "        out = torch.cat([out, node_feats], dim=1)\n",
    "        out = self.linears2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'methods'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmath\u001b[39;00m \u001b[39mimport\u001b[39;00m floor, ceil\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmethods\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstan\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstan_2d\u001b[39;00m \u001b[39mimport\u001b[39;00m stan_2d_model\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, confusion_matrix, roc_auc_score, f1_score, average_precision_score\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'methods'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "\n",
    "\n",
    "class TransactionGCN(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats, g, device):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(in_feats, hidden_feats,\n",
    "                               allow_zero_in_degree=True)\n",
    "        self.conv2 = GraphConv(hidden_feats, out_feats,\n",
    "                               allow_zero_in_degree=True)\n",
    "        self.lin1 = nn.Linear(in_feats, hidden_feats)\n",
    "        self.lin2 = nn.Linear(hidden_feats, out_feats)\n",
    "\n",
    "        g.ndata['feat'] = torch.nn.init.xavier_uniform_(torch.empty(\n",
    "            g.num_nodes(), g.edata['feat'].shape[1])).to(torch.float32).to(device)\n",
    "        g.ndata['h'] = g.ndata['feat']\n",
    "        g.edata['x'] = g.edata['feat']\n",
    "\n",
    "    def forward(self, g, h, e):\n",
    "        h1 = torch.relu(self.conv1(g, h))\n",
    "        e1 = torch.relu(self.lin1(e))\n",
    "        g.ndata['h'] = h1\n",
    "        g.edata['x'] = e1\n",
    "        g.apply_edges(\n",
    "            lambda edges: {'x': edges.src['h'] + edges.dst['h'] + edges.data['x']})\n",
    "\n",
    "        h2 = self.conv2(g, h1)\n",
    "        e2 = torch.relu(self.lin2(e1))\n",
    "        g.ndata['h'] = h2\n",
    "        g.edata['x'] = e2\n",
    "        g.apply_edges(\n",
    "            lambda edges: {'x': edges.src['h'] + edges.dst['h'] + edges.data['x']})\n",
    "        return g.ndata['h'], g.edata['x']\n",
    "\n",
    "\n",
    "class stagn_2d_model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        time_windows_dim: int,\n",
    "        feat_dim: int,\n",
    "        num_classes: int,\n",
    "        attention_hidden_dim: int,\n",
    "        g: dgl.DGLGraph,\n",
    "        filter_sizes: tuple = (2, 2),\n",
    "        num_filters: int = 64,\n",
    "        in_channels: int = 1,\n",
    "        device=\"cpu\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the STAGN-2d model\n",
    "\n",
    "        Args:\n",
    "        :param time_windows_dim (int): length of time windows\n",
    "        :param feat_dim (int): feature dimension\n",
    "        :param num_classes (int): number of classes\n",
    "        :param attention_hidden_dim (int): attention hidden dimenstion\n",
    "        :param g (dgl.DGLGraph): dgl graph for gcn embeddings\n",
    "        :param filter_sizes (tuple, optional): cnn filter size\n",
    "        :param num_filters (int, optional): number of hidden channels\n",
    "        :param in_channels (int, optional): number of in channels\n",
    "        :param device (str, optional): where to train the model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.time_windows_dim = time_windows_dim\n",
    "        self.feat_dim = feat_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.num_filters = num_filters\n",
    "\n",
    "        self.graph = g.to(device)\n",
    "\n",
    "        # attention layer\n",
    "        self.attention_W = nn.Parameter(torch.Tensor(\n",
    "            self.feat_dim, self.attention_hidden_dim).uniform_(0., 1.))\n",
    "        self.attention_U = nn.Parameter(torch.Tensor(\n",
    "            self.feat_dim, self.attention_hidden_dim).uniform_(0., 1.))\n",
    "        self.attention_V = nn.Parameter(torch.Tensor(\n",
    "            self.attention_hidden_dim, 1).uniform_(0., 1.))\n",
    "\n",
    "        # cnn layer\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=num_filters,\n",
    "            kernel_size=filter_sizes,\n",
    "            padding='same'\n",
    "        )\n",
    "\n",
    "        # FC layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linears1 = nn.Sequential(\n",
    "            nn.LazyLinear(256),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(24),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.linears2 = nn.LazyLinear(self.num_classes)\n",
    "\n",
    "        # gnn for transaction graph\n",
    "        self.gcn = TransactionGCN(\n",
    "            g.edata['feat'].shape[1], 128, 8, g, device)\n",
    "\n",
    "    def attention_layer(\n",
    "        self,\n",
    "        X: torch.Tensor\n",
    "    ):\n",
    "        self.output_att = []\n",
    "        # input_att = torch.split(X, self.time_windows_dim, dim=1)\n",
    "        input_att = torch.split(X, 1, dim=1)  # 第二个参数是split_size!\n",
    "        for index, x_i in enumerate(input_att):\n",
    "            # print(f\"x_i shape: {x_i.shape}\")\n",
    "            x_i = x_i.reshape(-1, self.feat_dim)\n",
    "            c_i = self.attention(x_i, input_att, index)\n",
    "            inp = torch.concat([x_i, c_i], axis=1)\n",
    "            self.output_att.append(inp)\n",
    "\n",
    "        input_conv = torch.reshape(torch.concat(self.output_att, axis=1),\n",
    "                                   [-1, self.time_windows_dim, self.feat_dim*2])\n",
    "\n",
    "        self.input_conv_expanded = torch.unsqueeze(input_conv, 1)\n",
    "\n",
    "        return self.input_conv_expanded\n",
    "\n",
    "    def cnn_layer(\n",
    "        self,\n",
    "        input: torch.Tensor\n",
    "    ):\n",
    "        if len(input.shape) == 3:\n",
    "            self.input_conv_expanded = torch.unsqueeze(input, 1)\n",
    "        elif len(input.shape) == 4:\n",
    "            self.input_conv_expanded = input\n",
    "        else:\n",
    "            print(\"Wrong conv input shape!\")\n",
    "\n",
    "        self.input_conv_expanded = F.relu(self.conv(input))\n",
    "\n",
    "        return self.input_conv_expanded\n",
    "\n",
    "    def attention(self, x_i, x, index):\n",
    "        e_i = []\n",
    "        c_i = []\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            output = x[i]\n",
    "            output = output.reshape(-1, self.feat_dim)\n",
    "            att_hidden = torch.tanh(torch.add(torch.matmul(\n",
    "                x_i, self.attention_W), torch.matmul(output, self.attention_U)))\n",
    "            e_i_j = torch.matmul(att_hidden, self.attention_V)\n",
    "            e_i.append(e_i_j)\n",
    "\n",
    "        e_i = torch.concat(e_i, axis=1)\n",
    "        # print(f\"e_i shape: {e_i.shape}\")\n",
    "        alpha_i = F.softmax(e_i, dim=1)\n",
    "        alpha_i = torch.split(alpha_i, 1, 1)  # !!!\n",
    "\n",
    "        for j, (alpha_i_j, output) in enumerate(zip(alpha_i, x)):\n",
    "            if j == index:\n",
    "                continue\n",
    "            else:\n",
    "                output = output.reshape(-1, self.feat_dim)\n",
    "                c_i_j = torch.multiply(alpha_i_j, output)\n",
    "                c_i.append(c_i_j)\n",
    "\n",
    "        c_i = torch.reshape(torch.concat(c_i, axis=1),\n",
    "                            [-1, self.time_windows_dim-1, self.feat_dim])\n",
    "        c_i = torch.sum(c_i, dim=1)\n",
    "        return c_i\n",
    "\n",
    "    def forward(self, X_nume, g):\n",
    "        # X shape be like: (batch_size, time_windows_dim, feat_dim)\n",
    "        out = self.attention_layer(X_nume)  # all, 1, 8, 10\n",
    "\n",
    "        out = self.cnn_layer(out)  # all, 64, 8, 10\n",
    "        node_embs, edge_embs = self.gcn(g, g.ndata['feat'], g.edata['feat'])\n",
    "\n",
    "        src_nds, dst_nds = g.edges()\n",
    "        src_feat = g.ndata['h'][src_nds]\n",
    "        dst_feat = g.ndata['h'][dst_nds]\n",
    "        # all, 3, embedding_dim\n",
    "        node_feats = torch.stack(\n",
    "            [src_feat, dst_feat, edge_embs], dim=1).view(X_nume.shape[0], -1)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linears1(out)\n",
    "        out = torch.cat([out, node_feats], dim=1)\n",
    "        out = self.linears2(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_load_data(args: dict):\n",
    "    # load S-FFSD dataset for base models\n",
    "    data_path = \"data/S-FFSD.csv\"\n",
    "    feat_df = pd.read_csv(data_path)\n",
    "    train_size = 1 - args['test_size']\n",
    "    method = args['method']\n",
    "    # for ICONIP16 & AAAI20\n",
    "    if os.path.exists(\"data/tel_2d.npy\"):\n",
    "        return\n",
    "    features, labels = span_data_2d(feat_df)\n",
    "    num_trans = len(feat_df)\n",
    "    trf, tef, trl, tel = train_test_split(\n",
    "        features, labels, train_size=train_size, stratify=labels, shuffle=True)\n",
    "    trf_file, tef_file, trl_file, tel_file = args['trainfeature'], args[\n",
    "        'testfeature'], args['trainlabel'], args['testlabel']\n",
    "    np.save(trf_file, trf)\n",
    "    np.save(tef_file, tef)\n",
    "    np.save(trl_file, trl)\n",
    "    np.save(tel_file, tel)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_load_data(args)\n",
    "stan_main(\n",
    "    args['trainfeature'],\n",
    "    args['trainlabel'],\n",
    "    args['testfeature'],\n",
    "    args['testlabel'],\n",
    "    mode='2d',\n",
    "    epochs=args['epochs'],\n",
    "    batch_size=args['batch_size'],\n",
    "    attention_hidden_dim=args['attention_hidden_dim'],\n",
    "    lr=args['lr'],\n",
    "    device=torch.device('cpu')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
