{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import Linear, LayerNorm, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import ChebConv, NNConv, DeepGCNLayer, GATConv, DenseGCNConv, GCNConv, GraphConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ref: https://medium.com/stanford-cs224w/fraud-detection-with-gat-edac49bda1a0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate txId:  0\n"
     ]
    }
   ],
   "source": [
    "# import data \n",
    "df_features = pd.read_csv('../data/elliptic_txs_features.csv', header=None)\n",
    "df_edges = pd.read_csv(\"../data/elliptic_txs_edgelist.csv\")\n",
    "df_classes =  pd.read_csv(\"../data/elliptic_txs_classes.csv\")\n",
    "\n",
    "df_classes['class'] = df_classes['class'].map({'unknown': 2, '1':1, '2':0})\n",
    "\n",
    "# merging dataframes\n",
    "df_merge = df_features.merge(df_classes, how='left', right_on=\"txId\", left_on=0)\n",
    "df_merge.drop(0, axis=1, inplace=True)\n",
    "\n",
    "# check if there are duplicate txId\n",
    "print(\"Number of duplicate txId: \", df_merge.duplicated(subset=['txId']).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>txId</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162097</td>\n",
       "      <td>-0.167933</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>230425980</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162112</td>\n",
       "      <td>-0.167948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>5530458</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162749</td>\n",
       "      <td>-0.168576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>232022460</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>-0.163645</td>\n",
       "      <td>-0.115831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>232438397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163523</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "      <td>230460314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step         2         3         4          5         6         7  \\\n",
       "0          1 -0.171469 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "1          1 -0.171484 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "2          1 -0.172107 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "3          1  0.163054  1.963790 -0.646376  12.409294 -0.063725  9.782742   \n",
       "4          1  1.011523 -0.081127 -1.201369   1.153668  0.333276  1.312656   \n",
       "\n",
       "           8         9        10  ...       159       160       161       162  \\\n",
       "0  -0.061584 -0.162097 -0.167933  ...  1.461330  1.461369  0.018279 -0.087490   \n",
       "1  -0.061584 -0.162112 -0.167948  ... -0.979074 -0.978556  0.018279 -0.087490   \n",
       "2  -0.061584 -0.162749 -0.168576  ... -0.979074 -0.978556 -0.098889 -0.106715   \n",
       "3  12.414558 -0.163645 -0.115831  ...  0.241128  0.241406  1.072793  0.085530   \n",
       "4  -0.061584 -0.163523  0.041399  ...  0.517257  0.579382  0.018279  0.277775   \n",
       "\n",
       "        163       164       165       166       txId  class  \n",
       "0 -0.131155 -0.097524 -0.120613 -0.119792  230425980      2  \n",
       "1 -0.131155 -0.097524 -0.120613 -0.119792    5530458      2  \n",
       "2 -0.131155 -0.183671 -0.120613 -0.119792  232022460      2  \n",
       "3 -0.131155  0.677799 -0.120613 -0.119792  232438397      0  \n",
       "4  0.326394  1.293750  0.178136  0.179117  230460314      2  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(234355, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rename column 0 to time_step\n",
    "df_merge.rename(columns={1: 'time_step'}, inplace=True)\n",
    "display(df_merge.head())\n",
    "display(df_edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203769, 168)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of edge index is torch.Size([2, 234355])\n"
     ]
    }
   ],
   "source": [
    "edges = df_edges.copy()\n",
    "\n",
    "# Setup trans ID to node ID mapping\n",
    "nodes = df_merge['txId'].values\n",
    "map_id = {j:i for i,j in enumerate(nodes)} # mapping nodes to indexes\n",
    "\n",
    "# Map transction IDs to node Ids\n",
    "edges.txId1 = edges.txId1.map(map_id) #get nodes idx1 from edges list and filtered data\n",
    "edges.txId2 = edges.txId2.map(map_id)\n",
    "edges = edges.astype(int)\n",
    "\n",
    "# Reformat and convert to tensor\n",
    "edge_index = np.array(edges.values).T \n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).contiguous()\n",
    "\n",
    "print(\"shape of edge index is {}\".format(edge_index.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique= [2 0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162097</td>\n",
       "      <td>-0.167933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162112</td>\n",
       "      <td>-0.167948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673103</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162749</td>\n",
       "      <td>-0.168576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439728</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>-0.163645</td>\n",
       "      <td>-0.115831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163523</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400422</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step         2         3         4          5         6         7  \\\n",
       "0          1 -0.171469 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "1          1 -0.171484 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "2          1 -0.172107 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "3          1  0.163054  1.963790 -0.646376  12.409294 -0.063725  9.782742   \n",
       "4          1  1.011523 -0.081127 -1.201369   1.153668  0.333276  1.312656   \n",
       "\n",
       "           8         9        10  ...       158       159       160       161  \\\n",
       "0  -0.061584 -0.162097 -0.167933  ... -0.600999  1.461330  1.461369  0.018279   \n",
       "1  -0.061584 -0.162112 -0.167948  ...  0.673103 -0.979074 -0.978556  0.018279   \n",
       "2  -0.061584 -0.162749 -0.168576  ...  0.439728 -0.979074 -0.978556 -0.098889   \n",
       "3  12.414558 -0.163645 -0.115831  ... -0.613614  0.241128  0.241406  1.072793   \n",
       "4  -0.061584 -0.163523  0.041399  ... -0.400422  0.517257  0.579382  0.018279   \n",
       "\n",
       "        162       163       164       165       166  class  \n",
       "0 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792      2  \n",
       "1 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792      2  \n",
       "2 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792      2  \n",
       "3  0.085530 -0.131155  0.677799 -0.120613 -0.119792      0  \n",
       "4  0.277775  0.326394  1.293750  0.178136  0.179117      2  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_features = df_merge.drop(['txId'], axis=1).copy()\n",
    "print(\"unique=\",node_features[\"class\"].unique())\n",
    "\n",
    "# Retain known vs unknown IDs\n",
    "all_classified_idx = node_features['class'].loc[node_features['class']!=2].index # filter on known labels\n",
    "all_unclassified_idx = node_features['class'].loc[node_features['class']==2].index\n",
    "all_classified_illicit_idx = node_features['class'].loc[node_features['class']==1].index # filter on illicit labels\n",
    "all_classified_licit_idx = node_features['class'].loc[node_features['class']==0].index # filter on licit labels\n",
    "\n",
    "# node_features = node_features.drop(columns=[0, 1, 'class'])\n",
    "display(node_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203769, 168)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_classified_idx.shape= (29894,)\n",
      "test_classified_idx.shape= (16670,)\n"
     ]
    }
   ],
   "source": [
    "train_classified_idx = node_features.loc[(node_features['time_step'] <= 34) & (node_features['class'] != 2)].index\n",
    "test_classified_idx = node_features.loc[(node_features['time_step'] > 34) & (node_features['class'] != 2)].index\n",
    "print(\"train_classified_idx.shape=\",train_classified_idx.shape)\n",
    "print(\"test_classified_idx.shape=\",test_classified_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_features.drop(columns=['time_step'], inplace=True)\n",
    "node_features.drop(columns=['class'], inplace=True)\n",
    "\n",
    "# Convert to tensor\n",
    "node_features_t = torch.tensor(np.array(node_features.values, dtype=np.double), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[203769, 166], edge_index=[2, 234355], edge_attr=[234355], y=[203769], train_idx=Int64Index([     3,      9,     10,     11,     16,     17,     25,     27,\n",
       "                29,     30,\n",
       "            ...\n",
       "            136232, 136233, 136234, 136236, 136239, 136241, 136243, 136249,\n",
       "            136250, 136258],\n",
       "           dtype='int64', length=29894), test_idx=Int64Index([136276, 136277, 136278, 136279, 136280, 136282, 136285, 136287,\n",
       "            136288, 136291,\n",
       "            ...\n",
       "            203727, 203730, 203736, 203740, 203750, 203752, 203754, 203759,\n",
       "            203763, 203766],\n",
       "           dtype='int64', length=16670))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define labels\n",
    "labels = df_merge['class'].values\n",
    "\n",
    "#create weights tensor with same shape of edge_index\n",
    "weights = torch.tensor([1]* edge_index.shape[1] , dtype=torch.double) \n",
    "\n",
    "# Do train test split on classified_ids\n",
    "train_idx = train_classified_idx\n",
    "test_idx = test_classified_idx\n",
    "\n",
    "# Create pyG dataset\n",
    "data_graph = Data(x=node_features_t.float(), edge_index=edge_index, edge_attr=weights, \n",
    "                               y=torch.tensor(labels, dtype=torch.long))\n",
    "\n",
    "# Add in the train and valid idx\n",
    "data_graph.train_idx = train_idx\n",
    "data_graph.test_idx = test_idx\n",
    "data_graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STAGN Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class TGCN(torch.nn.Module):\n",
    "    r\"\"\"An implementation of the Temporal Graph Convolutional Gated Recurrent Cell.\n",
    "    For details see this paper: `\"T-GCN: A Temporal Graph ConvolutionalNetwork for\n",
    "    Traffic Prediction.\" <https://arxiv.org/abs/1811.05320>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        improved (bool): Stronger self loops. Default is False.\n",
    "        cached (bool): Caching the message weights. Default is False.\n",
    "        add_self_loops (bool): Adding self-loops for smoothing. Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        improved: bool = False,\n",
    "        cached: bool = False,\n",
    "        add_self_loops: bool = True,\n",
    "    ):\n",
    "        super(TGCN, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self._create_parameters_and_layers()\n",
    "\n",
    "    def _create_update_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_z = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_z = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_reset_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_r = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_r = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_candidate_state_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_h = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_h = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_update_gate_parameters_and_layers()\n",
    "        self._create_reset_gate_parameters_and_layers()\n",
    "        self._create_candidate_state_parameters_and_layers()\n",
    "\n",
    "    def _set_hidden_state(self, X, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H):\n",
    "        Z = torch.cat([self.conv_z(X, edge_index, edge_weight), H], axis=1)\n",
    "        Z = self.linear_z(Z)\n",
    "        Z = torch.sigmoid(Z)\n",
    "        return Z\n",
    "\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n",
    "        R = torch.cat([self.conv_r(X, edge_index, edge_weight), H], axis=1)\n",
    "        R = self.linear_r(R)\n",
    "        R = torch.sigmoid(R)\n",
    "        return R\n",
    "\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n",
    "        H_tilde = torch.cat([self.conv_h(X, edge_index, edge_weight), H * R], axis=1)\n",
    "        H_tilde = self.linear_h(H_tilde)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "        return H_tilde\n",
    "\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde):\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        return H\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.FloatTensor,\n",
    "        edge_index: torch.LongTensor,\n",
    "        edge_weight: torch.FloatTensor = None,\n",
    "        H: torch.FloatTensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Making a forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph. If the hidden state matrix is not present\n",
    "        when the forward pass is called it is initialized with zeros.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** *(PyTorch Float Tensor)* - Node features.\n",
    "            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n",
    "            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n",
    "            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n",
    "\n",
    "        Return types:\n",
    "            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n",
    "        \"\"\"\n",
    "        H = self._set_hidden_state(X, H)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde)\n",
    "        return H\n",
    "\n",
    "\n",
    "class TGCN2(torch.nn.Module):\n",
    "    r\"\"\"An implementation THAT SUPPORTS BATCHES of the Temporal Graph Convolutional Gated Recurrent Cell.\n",
    "    For details see this paper: `\"T-GCN: A Temporal Graph ConvolutionalNetwork for\n",
    "    Traffic Prediction.\" <https://arxiv.org/abs/1811.05320>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        batch_size (int): Size of the batch.\n",
    "        improved (bool): Stronger self loops. Default is False.\n",
    "        cached (bool): Caching the message weights. Default is False.\n",
    "        add_self_loops (bool): Adding self-loops for smoothing. Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, \n",
    "                 batch_size: int,  # this entry is unnecessary, kept only for backward compatibility\n",
    "                 improved: bool = False, cached: bool = False, \n",
    "                 add_self_loops: bool = True):\n",
    "        super(TGCN2, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "        self.add_self_loops = add_self_loops\n",
    "        self.batch_size = batch_size  # not needed\n",
    "        self._create_parameters_and_layers()\n",
    "\n",
    "    def _create_update_gate_parameters_and_layers(self):\n",
    "        self.conv_z = GCNConv(in_channels=self.in_channels,  out_channels=self.out_channels, improved=self.improved,\n",
    "                              cached=self.cached, add_self_loops=self.add_self_loops )\n",
    "        self.linear_z = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_reset_gate_parameters_and_layers(self):\n",
    "        self.conv_r = GCNConv(in_channels=self.in_channels, out_channels=self.out_channels, improved=self.improved,\n",
    "                              cached=self.cached, add_self_loops=self.add_self_loops )\n",
    "        self.linear_r = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_candidate_state_parameters_and_layers(self):\n",
    "        self.conv_h = GCNConv(in_channels=self.in_channels, out_channels=self.out_channels, improved=self.improved,\n",
    "                              cached=self.cached, add_self_loops=self.add_self_loops )\n",
    "        self.linear_h = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_update_gate_parameters_and_layers()\n",
    "        self._create_reset_gate_parameters_and_layers()\n",
    "        self._create_candidate_state_parameters_and_layers()\n",
    "\n",
    "    def _set_hidden_state(self, X, H):\n",
    "        if H is None:\n",
    "            # can infer batch_size from X.shape, because X is [B, N, F]\n",
    "            H = torch.zeros(X.shape[0], X.shape[1], self.out_channels).to(X.device) #(b, 207, 32)\n",
    "        return H\n",
    "\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H):\n",
    "        Z = torch.cat([self.conv_z(X, edge_index, edge_weight), H], axis=2) # (b, 207, 64)\n",
    "        Z = self.linear_z(Z) # (b, 207, 32)\n",
    "        Z = torch.sigmoid(Z)\n",
    "\n",
    "        return Z\n",
    "\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n",
    "        R = torch.cat([self.conv_r(X, edge_index, edge_weight), H], axis=2) # (b, 207, 64)\n",
    "        R = self.linear_r(R) # (b, 207, 32)\n",
    "        R = torch.sigmoid(R)\n",
    "\n",
    "        return R\n",
    "\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n",
    "        H_tilde = torch.cat([self.conv_h(X, edge_index, edge_weight), H * R], axis=2) # (b, 207, 64)\n",
    "        H_tilde = self.linear_h(H_tilde) # (b, 207, 32)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "\n",
    "        return H_tilde\n",
    "\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde):\n",
    "        H = Z * H + (1 - Z) * H_tilde   # # (b, 207, 32)\n",
    "        return H\n",
    "\n",
    "    def forward(self,X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor = None,\n",
    "                H: torch.FloatTensor = None ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Making a forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph. If the hidden state matrix is not present\n",
    "        when the forward pass is called it is initialized with zeros.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** *(PyTorch Float Tensor)* - Node features.\n",
    "            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n",
    "            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n",
    "            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n",
    "\n",
    "        Return types:\n",
    "            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n",
    "        \"\"\"\n",
    "        H = self._set_hidden_state(X, H)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde) # (b, 207, 32)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = data_graph.num_node_features\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    # out = out.reshape((data.x.shape[0]))\n",
    "    # TODO :use weighted cross entropy loss\n",
    "    loss = F.cross_entropy(out[data.train_idx], data.y[data.train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred_scores = out[data.test_idx]\n",
    "        pred = torch.argmax(pred_scores, dim=1)\n",
    "        # print(sum([1 for i in pred.tolist() if i == 1]))\n",
    "        y = data.y[data.test_idx]\n",
    "        acc = accuracy_score(y.cpu(), pred.cpu())\n",
    "        f1 = f1_score(y.cpu(), pred.cpu())\n",
    "        precision = precision_score(y.cpu(), pred.cpu())\n",
    "        recall = recall_score(y.cpu(), pred.cpu())\n",
    "        roc = roc_auc_score(y.cpu(), pred.cpu())\n",
    "        return acc, f1, precision, recall, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tgcn = TGCN(in_channels=num_features, out_channels=2)\n",
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model_tgcn.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs+1):\n",
    "    loss = train(model_tgcn, data_graph, optimizer)\n",
    "    acc, f1, precision, recall, roc = test(model_tgcn, data_graph)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}, Acc: {acc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, recall: {recall:.4f}, roc: {roc:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9344, F1: 0.0000, Precision: 0.0000, Recall: 0.0000, ROC: 0.4996\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "acc, f1, precision, recall, roc = test(model_tgcn, data_graph)\n",
    "print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, ROC: {roc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConv(torch.nn.Module):\n",
    "    r\"\"\"Temporal convolution block applied to nodes in the STGCN Layer\n",
    "    For details see: `\"Spatio-Temporal Graph Convolutional Networks:\n",
    "    A Deep Learning Framework for Traffic Forecasting.\"\n",
    "    <https://arxiv.org/abs/1709.04875>`_ Based off the temporal convolution\n",
    "     introduced in \"Convolutional Sequence to Sequence Learning\"  <https://arxiv.org/abs/1709.04875>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        kernel_size (int): Convolutional kernel size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int = 3):\n",
    "        super(TemporalConv, self).__init__()\n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv_3 = torch.nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "\n",
    "    def forward(self, X: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Forward pass through temporal convolution block.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** (torch.FloatTensor) -  Input data of shape\n",
    "                (batch_size, input_time_steps, num_nodes, in_channels).\n",
    "\n",
    "        Return types:\n",
    "            * **H** (torch.FloatTensor) - Output data of shape\n",
    "                (batch_size, in_channels, num_nodes, input_time_steps).\n",
    "        \"\"\"\n",
    "        X = X.permute(0, 3, 2, 1)\n",
    "        P = self.conv_1(X)\n",
    "        Q = torch.sigmoid(self.conv_2(X))\n",
    "        PQ = P * Q\n",
    "        H = F.relu(PQ + self.conv_3(X))\n",
    "        H = H.permute(0, 3, 2, 1)\n",
    "        return H\n",
    "\n",
    "class STConv(torch.nn.Module):\n",
    "    r\"\"\"Spatio-temporal convolution block using ChebConv Graph Convolutions.\n",
    "    For details see: `\"Spatio-Temporal Graph Convolutional Networks:\n",
    "    A Deep Learning Framework for Traffic Forecasting\"\n",
    "    <https://arxiv.org/abs/1709.04875>`_\n",
    "\n",
    "    NB. The ST-Conv block contains two temporal convolutions (TemporalConv)\n",
    "    with kernel size k. Hence for an input sequence of length m,\n",
    "    the output sequence will be length m-2*(k-1).\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        hidden_channels (int): Number of hidden units output by graph convolution block\n",
    "        out_channels (int): Number of output features.\n",
    "        kernel_size (int): Size of the kernel considered.\n",
    "        K (int): Chebyshev filter size :math:`K`.\n",
    "        normalization (str, optional): The normalization scheme for the graph\n",
    "            Laplacian (default: :obj:`\"sym\"`):\n",
    "\n",
    "            1. :obj:`None`: No normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n",
    "\n",
    "            2. :obj:`\"sym\"`: Symmetric normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n",
    "            \\mathbf{D}^{-1/2}`\n",
    "\n",
    "            3. :obj:`\"rw\"`: Random-walk normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n",
    "\n",
    "            You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n",
    "            this operator in case the normalization is non-symmetric.\n",
    "            :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n",
    "            :obj:`[num_graphs]` in a mini-batch scenario and a\n",
    "            scalar/zero-dimensional tensor when operating on single graphs.\n",
    "            You can pre-compute :obj:`lambda_max` via the\n",
    "            :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        in_channels: int,\n",
    "        hidden_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        K: int,\n",
    "        normalization: str = \"sym\",\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        super(STConv, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.K = K\n",
    "        self.normalization = normalization\n",
    "        self.bias = bias\n",
    "\n",
    "        self._temporal_conv1 = TemporalConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "        )\n",
    "\n",
    "        self._graph_conv = ChebConv(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            K=K,\n",
    "            normalization=normalization,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        self._temporal_conv2 = TemporalConv(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "        )\n",
    "\n",
    "        self._batch_norm = torch.nn.BatchNorm2d(num_nodes)\n",
    "\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.FloatTensor,\n",
    "        edge_index: torch.LongTensor,\n",
    "        edge_weight: torch.FloatTensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "\n",
    "        r\"\"\"Forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** (PyTorch FloatTensor) - Sequence of node features of shape (Batch size X Input time steps X Num nodes X In channels).\n",
    "            * **edge_index** (PyTorch LongTensor) - Graph edge indices.\n",
    "            * **edge_weight** (PyTorch LongTensor, optional)- Edge weight vector.\n",
    "\n",
    "        Return types:\n",
    "            * **T** (PyTorch FloatTensor) - Sequence of node features.\n",
    "        \"\"\"\n",
    "        T_0 = self._temporal_conv1(X)\n",
    "        T = torch.zeros_like(T_0).to(T_0.device)\n",
    "        for b in range(T_0.size(0)):\n",
    "            for t in range(T_0.size(1)):\n",
    "                T[b][t] = self._graph_conv(T_0[b][t], edge_index, edge_weight)\n",
    "\n",
    "        T = F.relu(T)\n",
    "        T = self._temporal_conv2(T)\n",
    "        T = T.permute(0, 2, 1, 3)\n",
    "        T = self._batch_norm(T)\n",
    "        T = T.permute(0, 2, 1, 3)\n",
    "        return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stconv(model, data, optimizer):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    X = data_graph.x.unsqueeze(axis=0).unsqueeze(axis=0)\n",
    "    out = model(X, data.edge_index)\n",
    "    # out = out.reshape((data.x.shape[0]))\n",
    "    out = out.squeeze()\n",
    "    # TODO :use weighted cross entropy loss\n",
    "    loss = F.cross_entropy(out[data.train_idx], data.y[data.train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test_stconv(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        X = data_graph.x.unsqueeze(axis=0).unsqueeze(axis=0)\n",
    "        out = model(X, data.edge_index)\n",
    "        out = out.squeeze()\n",
    "        pred_scores = out[data.test_idx]\n",
    "        pred = torch.argmax(pred_scores, dim=1)\n",
    "        # print(sum([1 for i in pred.tolist() if i == 1]))\n",
    "        y = data.y[data.test_idx]\n",
    "        acc = accuracy_score(y.cpu(), pred.cpu())\n",
    "        f1 = f1_score(y.cpu(), pred.cpu())\n",
    "        precision = precision_score(y.cpu(), pred.cpu())\n",
    "        recall = recall_score(y.cpu(), pred.cpu())\n",
    "        roc = roc_auc_score(y.cpu(), pred.cpu())\n",
    "        return acc, f1, precision, recall, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.5432, acc: 0.6653, f1: 0.0894, precision: 0.0543, recall: 0.2530, roc: 0.4735\n",
      "epoch: 1, loss: 0.8417, acc: 0.8831, f1: 0.0279, precision: 0.0304, recall: 0.0259, roc: 0.4843\n",
      "epoch: 2, loss: 0.8019, acc: 0.7385, f1: 0.1181, precision: 0.0756, recall: 0.2696, roc: 0.5204\n",
      "epoch: 3, loss: 1.0054, acc: 0.5893, f1: 0.1081, precision: 0.0629, recall: 0.3832, roc: 0.4934\n",
      "epoch: 4, loss: 1.0929, acc: 0.6166, f1: 0.1050, precision: 0.0619, recall: 0.3463, roc: 0.4908\n",
      "epoch: 5, loss: 1.0620, acc: 0.6160, f1: 0.1021, precision: 0.0602, recall: 0.3361, roc: 0.4858\n",
      "epoch: 6, loss: 1.0573, acc: 0.5957, f1: 0.0968, precision: 0.0566, recall: 0.3333, roc: 0.4737\n",
      "epoch: 7, loss: 1.0859, acc: 0.6056, f1: 0.0930, precision: 0.0547, recall: 0.3112, roc: 0.4686\n",
      "epoch: 8, loss: 1.0771, acc: 0.6041, f1: 0.0894, precision: 0.0526, recall: 0.2992, roc: 0.4622\n",
      "epoch: 9, loss: 1.0898, acc: 0.6065, f1: 0.0894, precision: 0.0526, recall: 0.2973, roc: 0.4626\n",
      "epoch: 10, loss: 1.1016, acc: 0.6001, f1: 0.0876, precision: 0.0514, recall: 0.2955, roc: 0.4583\n",
      "epoch: 11, loss: 1.1453, acc: 0.6037, f1: 0.0883, precision: 0.0519, recall: 0.2955, roc: 0.4603\n",
      "epoch: 12, loss: 1.1764, acc: 0.5893, f1: 0.0860, precision: 0.0503, recall: 0.2973, roc: 0.4535\n",
      "epoch: 13, loss: 1.2298, acc: 0.5836, f1: 0.0851, precision: 0.0497, recall: 0.2982, roc: 0.4508\n",
      "epoch: 14, loss: 1.2504, acc: 0.5983, f1: 0.0875, precision: 0.0513, recall: 0.2964, roc: 0.4578\n",
      "epoch: 15, loss: 1.2241, acc: 0.5984, f1: 0.0875, precision: 0.0513, recall: 0.2964, roc: 0.4579\n",
      "epoch: 16, loss: 1.2301, acc: 0.5922, f1: 0.0865, precision: 0.0506, recall: 0.2973, roc: 0.4550\n",
      "epoch: 17, loss: 1.2598, acc: 0.5744, f1: 0.0837, precision: 0.0487, recall: 0.2992, roc: 0.4464\n",
      "epoch: 18, loss: 1.2869, acc: 0.5776, f1: 0.0843, precision: 0.0490, recall: 0.2992, roc: 0.4481\n",
      "epoch: 19, loss: 1.2809, acc: 0.5777, f1: 0.0845, precision: 0.0492, recall: 0.3001, roc: 0.4485\n",
      "epoch: 20, loss: 1.2883, acc: 0.5580, f1: 0.0827, precision: 0.0478, recall: 0.3066, roc: 0.4410\n"
     ]
    }
   ],
   "source": [
    "num_nodes = data_graph.x.shape[0]\n",
    "model_stconv = STConv(num_nodes=num_nodes, in_channels=num_features, hidden_channels=128, out_channels=2, \n",
    "                      kernel_size=1,K=2)\n",
    "optimizer_stconv = torch.optim.Adam(model_stconv.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(20+1):\n",
    "    loss = train_stconv(model_stconv, data_graph, optimizer_stconv)\n",
    "    acc, f1, precision, recall, roc = test_stconv(model_stconv, data_graph)\n",
    "    print(f'epoch: {epoch}, loss: {loss:.4f}, acc: {acc:.4f}, f1: {f1:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, roc: {roc:.4f}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
