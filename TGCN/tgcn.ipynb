{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import Linear, LayerNorm, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import ChebConv, NNConv, DeepGCNLayer, GATConv, DenseGCNConv, GCNConv, GraphConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ref: https://medium.com/stanford-cs224w/fraud-detection-with-gat-edac49bda1a0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate txId:  0\n"
     ]
    }
   ],
   "source": [
    "# import data \n",
    "df_features = pd.read_csv('../data/elliptic_txs_features.csv', header=None)\n",
    "df_edges = pd.read_csv(\"../data/elliptic_txs_edgelist.csv\")\n",
    "df_classes =  pd.read_csv(\"../data/elliptic_txs_classes.csv\")\n",
    "\n",
    "df_classes['class'] = df_classes['class'].map({'unknown': 2, '1':1, '2':0})\n",
    "\n",
    "# merging dataframes\n",
    "df_merge = df_features.merge(df_classes, how='left', right_on=\"txId\", left_on=0)\n",
    "df_merge.drop(0, axis=1, inplace=True)\n",
    "\n",
    "# check if there are duplicate txId\n",
    "print(\"Number of duplicate txId: \", df_merge.duplicated(subset=['txId']).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>txId</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162097</td>\n",
       "      <td>-0.167933</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>230425980</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162112</td>\n",
       "      <td>-0.167948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>5530458</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162749</td>\n",
       "      <td>-0.168576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>232022460</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>-0.163645</td>\n",
       "      <td>-0.115831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>232438397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163523</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "      <td>230460314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step         2         3         4          5         6         7  \\\n",
       "0          1 -0.171469 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "1          1 -0.171484 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "2          1 -0.172107 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "3          1  0.163054  1.963790 -0.646376  12.409294 -0.063725  9.782742   \n",
       "4          1  1.011523 -0.081127 -1.201369   1.153668  0.333276  1.312656   \n",
       "\n",
       "           8         9        10  ...       159       160       161       162  \\\n",
       "0  -0.061584 -0.162097 -0.167933  ...  1.461330  1.461369  0.018279 -0.087490   \n",
       "1  -0.061584 -0.162112 -0.167948  ... -0.979074 -0.978556  0.018279 -0.087490   \n",
       "2  -0.061584 -0.162749 -0.168576  ... -0.979074 -0.978556 -0.098889 -0.106715   \n",
       "3  12.414558 -0.163645 -0.115831  ...  0.241128  0.241406  1.072793  0.085530   \n",
       "4  -0.061584 -0.163523  0.041399  ...  0.517257  0.579382  0.018279  0.277775   \n",
       "\n",
       "        163       164       165       166       txId  class  \n",
       "0 -0.131155 -0.097524 -0.120613 -0.119792  230425980      2  \n",
       "1 -0.131155 -0.097524 -0.120613 -0.119792    5530458      2  \n",
       "2 -0.131155 -0.183671 -0.120613 -0.119792  232022460      2  \n",
       "3 -0.131155  0.677799 -0.120613 -0.119792  232438397      0  \n",
       "4  0.326394  1.293750  0.178136  0.179117  230460314      2  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(234355, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rename column 0 to time_step\n",
    "df_merge.rename(columns={1: 'time_step'}, inplace=True)\n",
    "display(df_merge.head())\n",
    "display(df_edges.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of edge index is torch.Size([2, 234355])\n"
     ]
    }
   ],
   "source": [
    "edges = df_edges.copy()\n",
    "\n",
    "# Setup trans ID to node ID mapping\n",
    "nodes = df_merge['txId'].values\n",
    "map_id = {j:i for i,j in enumerate(nodes)} # mapping nodes to indexes\n",
    "\n",
    "# Map transction IDs to node Ids\n",
    "edges.txId1 = edges.txId1.map(map_id) #get nodes idx1 from edges list and filtered data\n",
    "edges.txId2 = edges.txId2.map(map_id)\n",
    "edges = edges.astype(int)\n",
    "\n",
    "# Reformat and convert to tensor\n",
    "edge_index = np.array(edges.values).T \n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).contiguous()\n",
    "\n",
    "print(\"shape of edge index is {}\".format(edge_index.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique= [2 0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.171469</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162097</td>\n",
       "      <td>-0.167933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.600999</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.171484</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162112</td>\n",
       "      <td>-0.167948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673103</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.097524</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.172107</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.162749</td>\n",
       "      <td>-0.168576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439728</td>\n",
       "      <td>-0.979074</td>\n",
       "      <td>-0.978556</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>-0.183671</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>1.963790</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>12.409294</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>9.782742</td>\n",
       "      <td>12.414558</td>\n",
       "      <td>-0.163645</td>\n",
       "      <td>-0.115831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.613614</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>1.072793</td>\n",
       "      <td>0.085530</td>\n",
       "      <td>-0.131155</td>\n",
       "      <td>0.677799</td>\n",
       "      <td>-0.120613</td>\n",
       "      <td>-0.119792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.011523</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>1.153668</td>\n",
       "      <td>0.333276</td>\n",
       "      <td>1.312656</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163523</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400422</td>\n",
       "      <td>0.517257</td>\n",
       "      <td>0.579382</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.277775</td>\n",
       "      <td>0.326394</td>\n",
       "      <td>1.293750</td>\n",
       "      <td>0.178136</td>\n",
       "      <td>0.179117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step         2         3         4          5         6         7  \\\n",
       "0          1 -0.171469 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "1          1 -0.171484 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "2          1 -0.172107 -0.184668 -1.201369  -0.121970 -0.043875 -0.113002   \n",
       "3          1  0.163054  1.963790 -0.646376  12.409294 -0.063725  9.782742   \n",
       "4          1  1.011523 -0.081127 -1.201369   1.153668  0.333276  1.312656   \n",
       "\n",
       "           8         9        10  ...       158       159       160       161  \\\n",
       "0  -0.061584 -0.162097 -0.167933  ... -0.600999  1.461330  1.461369  0.018279   \n",
       "1  -0.061584 -0.162112 -0.167948  ...  0.673103 -0.979074 -0.978556  0.018279   \n",
       "2  -0.061584 -0.162749 -0.168576  ...  0.439728 -0.979074 -0.978556 -0.098889   \n",
       "3  12.414558 -0.163645 -0.115831  ... -0.613614  0.241128  0.241406  1.072793   \n",
       "4  -0.061584 -0.163523  0.041399  ... -0.400422  0.517257  0.579382  0.018279   \n",
       "\n",
       "        162       163       164       165       166  class  \n",
       "0 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792      2  \n",
       "1 -0.087490 -0.131155 -0.097524 -0.120613 -0.119792      2  \n",
       "2 -0.106715 -0.131155 -0.183671 -0.120613 -0.119792      2  \n",
       "3  0.085530 -0.131155  0.677799 -0.120613 -0.119792      0  \n",
       "4  0.277775  0.326394  1.293750  0.178136  0.179117      2  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_features = df_merge.drop(['txId'], axis=1).copy()\n",
    "print(\"unique=\",node_features[\"class\"].unique())\n",
    "\n",
    "# Retain known vs unknown IDs\n",
    "all_classified_idx = node_features['class'].loc[node_features['class']!=2].index # filter on known labels\n",
    "all_unclassified_idx = node_features['class'].loc[node_features['class']==2].index\n",
    "all_classified_illicit_idx = node_features['class'].loc[node_features['class']==1].index # filter on illicit labels\n",
    "all_classified_licit_idx = node_features['class'].loc[node_features['class']==0].index # filter on licit labels\n",
    "\n",
    "# node_features = node_features.drop(columns=[0, 1, 'class'])\n",
    "display(node_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_classified_idx.shape= (29894,)\n",
      "test_classified_idx.shape= (16670,)\n"
     ]
    }
   ],
   "source": [
    "train_classified_idx = node_features.loc[(node_features['time_step'] <= 34) & (node_features['class'] != 2)].index\n",
    "test_classified_idx = node_features.loc[(node_features['time_step'] > 34) & (node_features['class'] != 2)].index\n",
    "print(\"train_classified_idx.shape=\",train_classified_idx.shape)\n",
    "print(\"test_classified_idx.shape=\",test_classified_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/index/train_classified_idx.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# save the train and test indices as csv, integer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m np\u001b[39m.\u001b[39;49msavetxt(\u001b[39m\"\u001b[39;49m\u001b[39m../data/index/train_classified_idx.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, train_classified_idx, delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m, fmt\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m np\u001b[39m.\u001b[39msavetxt(\u001b[39m\"\u001b[39m\u001b[39m../data/index/test_classified_idx.csv\u001b[39m\u001b[39m\"\u001b[39m, test_classified_idx, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, fmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/gnn/lib/python3.10/site-packages/numpy/lib/npyio.py:1523\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1520\u001b[0m     fname \u001b[39m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1521\u001b[0m \u001b[39mif\u001b[39;00m _is_string_like(fname):\n\u001b[1;32m   1522\u001b[0m     \u001b[39m# datasource doesn't support creating a new file ...\u001b[39;00m\n\u001b[0;32m-> 1523\u001b[0m     \u001b[39mopen\u001b[39;49m(fname, \u001b[39m'\u001b[39;49m\u001b[39mwt\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1524\u001b[0m     fh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlib\u001b[39m.\u001b[39m_datasource\u001b[39m.\u001b[39mopen(fname, \u001b[39m'\u001b[39m\u001b[39mwt\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39mencoding)\n\u001b[1;32m   1525\u001b[0m     own_fh \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/index/train_classified_idx.csv'"
     ]
    }
   ],
   "source": [
    "# save the train and test indices as csv, integer\n",
    "np.savetxt(\"../data/index/train_classified_idx.csv\", train_classified_idx, delimiter=\",\", fmt='%d')\n",
    "np.savetxt(\"../data/index/test_classified_idx.csv\", test_classified_idx, delimiter=\",\", fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_features.drop(columns=['time_step'], inplace=True)\n",
    "node_features.drop(columns=['class'], inplace=True)\n",
    "\n",
    "# Convert to tensor\n",
    "node_features_t = torch.tensor(np.array(node_features.values, dtype=np.double), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[203769, 166], edge_index=[2, 234355], edge_attr=[234355], y=[203769], train_idx=Int64Index([     3,      9,     10,     11,     16,     17,     25,     27,\n",
       "                29,     30,\n",
       "            ...\n",
       "            136232, 136233, 136234, 136236, 136239, 136241, 136243, 136249,\n",
       "            136250, 136258],\n",
       "           dtype='int64', length=29894), test_idx=Int64Index([136276, 136277, 136278, 136279, 136280, 136282, 136285, 136287,\n",
       "            136288, 136291,\n",
       "            ...\n",
       "            203727, 203730, 203736, 203740, 203750, 203752, 203754, 203759,\n",
       "            203763, 203766],\n",
       "           dtype='int64', length=16670))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define labels\n",
    "labels = df_merge['class'].values\n",
    "\n",
    "#create weights tensor with same shape of edge_index\n",
    "weights = torch.tensor([1]* edge_index.shape[1] , dtype=torch.double) \n",
    "\n",
    "# Do train test split on classified_ids\n",
    "train_idx = train_classified_idx\n",
    "test_idx = test_classified_idx\n",
    "\n",
    "# Create pyG dataset\n",
    "data_graph = Data(x=node_features_t.float(), edge_index=edge_index, edge_attr=weights, \n",
    "                               y=torch.tensor(labels, dtype=torch.long))\n",
    "\n",
    "# Add in the train and valid idx\n",
    "data_graph.train_idx = train_idx\n",
    "data_graph.test_idx = test_idx\n",
    "data_graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STAGN Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class TGCN(torch.nn.Module):\n",
    "    r\"\"\"An implementation of the Temporal Graph Convolutional Gated Recurrent Cell.\n",
    "    For details see this paper: `\"T-GCN: A Temporal Graph ConvolutionalNetwork for\n",
    "    Traffic Prediction.\" <https://arxiv.org/abs/1811.05320>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        improved (bool): Stronger self loops. Default is False.\n",
    "        cached (bool): Caching the message weights. Default is False.\n",
    "        add_self_loops (bool): Adding self-loops for smoothing. Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        improved: bool = False,\n",
    "        cached: bool = False,\n",
    "        add_self_loops: bool = True,\n",
    "    ):\n",
    "        super(TGCN, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self._create_parameters_and_layers()\n",
    "\n",
    "    def _create_update_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_z = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_z = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_reset_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_r = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_r = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_candidate_state_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_h = GCNConv(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            improved=self.improved,\n",
    "            cached=self.cached,\n",
    "            add_self_loops=self.add_self_loops,\n",
    "        )\n",
    "\n",
    "        self.linear_h = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_update_gate_parameters_and_layers()\n",
    "        self._create_reset_gate_parameters_and_layers()\n",
    "        self._create_candidate_state_parameters_and_layers()\n",
    "\n",
    "    def _set_hidden_state(self, X, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H):\n",
    "        Z = torch.cat([self.conv_z(X, edge_index, edge_weight), H], axis=1)\n",
    "        Z = self.linear_z(Z)\n",
    "        Z = torch.sigmoid(Z)\n",
    "        return Z\n",
    "\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n",
    "        R = torch.cat([self.conv_r(X, edge_index, edge_weight), H], axis=1)\n",
    "        R = self.linear_r(R)\n",
    "        R = torch.sigmoid(R)\n",
    "        return R\n",
    "\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n",
    "        H_tilde = torch.cat([self.conv_h(X, edge_index, edge_weight), H * R], axis=1)\n",
    "        H_tilde = self.linear_h(H_tilde)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "        return H_tilde\n",
    "\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde):\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        return H\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.FloatTensor,\n",
    "        edge_index: torch.LongTensor,\n",
    "        edge_weight: torch.FloatTensor = None,\n",
    "        H: torch.FloatTensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Making a forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph. If the hidden state matrix is not present\n",
    "        when the forward pass is called it is initialized with zeros.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** *(PyTorch Float Tensor)* - Node features.\n",
    "            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n",
    "            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n",
    "            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n",
    "\n",
    "        Return types:\n",
    "            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n",
    "        \"\"\"\n",
    "        H = self._set_hidden_state(X, H)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde)\n",
    "        return H\n",
    "\n",
    "\n",
    "class TGCN2(torch.nn.Module):\n",
    "    r\"\"\"An implementation THAT SUPPORTS BATCHES of the Temporal Graph Convolutional Gated Recurrent Cell.\n",
    "    For details see this paper: `\"T-GCN: A Temporal Graph ConvolutionalNetwork for\n",
    "    Traffic Prediction.\" <https://arxiv.org/abs/1811.05320>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        batch_size (int): Size of the batch.\n",
    "        improved (bool): Stronger self loops. Default is False.\n",
    "        cached (bool): Caching the message weights. Default is False.\n",
    "        add_self_loops (bool): Adding self-loops for smoothing. Default is True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, \n",
    "                 batch_size: int,  # this entry is unnecessary, kept only for backward compatibility\n",
    "                 improved: bool = False, cached: bool = False, \n",
    "                 add_self_loops: bool = True):\n",
    "        super(TGCN2, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "        self.add_self_loops = add_self_loops\n",
    "        self.batch_size = batch_size  # not needed\n",
    "        self._create_parameters_and_layers()\n",
    "\n",
    "    def _create_update_gate_parameters_and_layers(self):\n",
    "        self.conv_z = GCNConv(in_channels=self.in_channels,  out_channels=self.out_channels, improved=self.improved,\n",
    "                              cached=self.cached, add_self_loops=self.add_self_loops )\n",
    "        self.linear_z = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_reset_gate_parameters_and_layers(self):\n",
    "        self.conv_r = GCNConv(in_channels=self.in_channels, out_channels=self.out_channels, improved=self.improved,\n",
    "                              cached=self.cached, add_self_loops=self.add_self_loops )\n",
    "        self.linear_r = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_candidate_state_parameters_and_layers(self):\n",
    "        self.conv_h = GCNConv(in_channels=self.in_channels, out_channels=self.out_channels, improved=self.improved,\n",
    "                              cached=self.cached, add_self_loops=self.add_self_loops )\n",
    "        self.linear_h = torch.nn.Linear(2 * self.out_channels, self.out_channels)\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_update_gate_parameters_and_layers()\n",
    "        self._create_reset_gate_parameters_and_layers()\n",
    "        self._create_candidate_state_parameters_and_layers()\n",
    "\n",
    "    def _set_hidden_state(self, X, H):\n",
    "        if H is None:\n",
    "            # can infer batch_size from X.shape, because X is [B, N, F]\n",
    "            H = torch.zeros(X.shape[0], X.shape[1], self.out_channels).to(X.device) #(b, 207, 32)\n",
    "        return H\n",
    "\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H):\n",
    "        Z = torch.cat([self.conv_z(X, edge_index, edge_weight), H], axis=2) # (b, 207, 64)\n",
    "        Z = self.linear_z(Z) # (b, 207, 32)\n",
    "        Z = torch.sigmoid(Z)\n",
    "\n",
    "        return Z\n",
    "\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n",
    "        R = torch.cat([self.conv_r(X, edge_index, edge_weight), H], axis=2) # (b, 207, 64)\n",
    "        R = self.linear_r(R) # (b, 207, 32)\n",
    "        R = torch.sigmoid(R)\n",
    "\n",
    "        return R\n",
    "\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n",
    "        H_tilde = torch.cat([self.conv_h(X, edge_index, edge_weight), H * R], axis=2) # (b, 207, 64)\n",
    "        H_tilde = self.linear_h(H_tilde) # (b, 207, 32)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "\n",
    "        return H_tilde\n",
    "\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde):\n",
    "        H = Z * H + (1 - Z) * H_tilde   # # (b, 207, 32)\n",
    "        return H\n",
    "\n",
    "    def forward(self,X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor = None,\n",
    "                H: torch.FloatTensor = None ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Making a forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph. If the hidden state matrix is not present\n",
    "        when the forward pass is called it is initialized with zeros.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** *(PyTorch Float Tensor)* - Node features.\n",
    "            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n",
    "            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n",
    "            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n",
    "\n",
    "        Return types:\n",
    "            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n",
    "        \"\"\"\n",
    "        H = self._set_hidden_state(X, H)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde) # (b, 207, 32)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = data_graph.num_node_features\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TGCN(\n",
       "  (conv_z): GCNConv(166, 2)\n",
       "  (linear_z): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (conv_r): GCNConv(166, 2)\n",
       "  (linear_r): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (conv_h): GCNConv(166, 2)\n",
       "  (linear_h): Linear(in_features=4, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tgcn = TGCN(in_channels=num_features, out_channels=2)\n",
    "num_epochs = 200\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model_tgcn.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    # out = out.reshape((data.x.shape[0]))\n",
    "    # TODO :use weighted cross entropy loss\n",
    "    loss = F.cross_entropy(out[data.train_idx], data.y[data.train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred_scores = out[data.test_idx]\n",
    "        pred = torch.argmax(pred_scores, dim=1)\n",
    "        y = data.y[data.test_idx]\n",
    "        acc = accuracy_score(y.cpu(), pred.cpu())\n",
    "        f1 = f1_score(y.cpu(), pred.cpu())\n",
    "        precision = precision_score(y.cpu(), pred.cpu())\n",
    "        recall = recall_score(y.cpu(), pred.cpu())\n",
    "        roc = roc_auc_score(y.cpu(), pred.cpu())\n",
    "        return acc, f1, precision, recall, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8443, F1: 0.3317, Precision: 0.2300, Recall: 0.5946, ROC: 0.7282\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "acc, f1, precision, recall, roc = test(model_tgcn, data_graph)\n",
    "print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, ROC: {roc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
